# Аналіз можливостей бібліотеки PaGMO2 для Генетичних Алгоритмів

## a. Загальна структура програми, що використовує бібліотеку

PaGMO2 (Parallel Global Multiobjective Optimizer) представляє собою високоефективну С++ наукову бібліотеку, спроектовану для масштабованої паралельної оптимізації. Архітектура бібліотеки базується на фундаментальному принципі уніфікованого інтерфейсу для різноманітних оптимізаційних алгоритмів та задач, з особливим акцентом на їх ефективне паралельне виконання у високопродуктивних обчислювальних середовищах.

### Архітектурні компоненти

#### 1. Problem (UDP - User Defined Problem)
Проблема є центральним компонентом, що інкапсулює математичну задачу оптимізації:

- **Формальна специфікація**: представляється як користувацький клас, що реалізує щонайменше два обов'язкові методи:
  - `fitness(const vector_double &dv)`: реалізує обчислення цільової функції (або функцій) та функцій обмежень
  - `get_bounds()`: визначає простір пошуку через задання мінімальних та максимальних значень змінних оптимізації

- **Стандартний інтерфейс**: містить додаткові опціональні методи, що розширюють функціональність:
  - `get_nobj()`: визначає кількість цільових функцій (для багатокритеріальної оптимізації)
  - `get_nec()`, `get_nic()`: визначають кількість рівностей та нерівностей для оптимізації з обмеженнями
  - `gradient()`, `hessians()`: надають аналітичні градієнти чи гессіани для методів, що ними користуються

#### 2. Algorithm (UDA - User Defined Algorithm)
Алгоритм представляє собою метод оптимізації:

- **Поліморфізм без успадкування**: PaGMO2 використовує механізм "стирання типу" (type erasure), де будь-який клас з методом `evolve()` може функціонувати як алгоритм

- **Когерентна таксономія алгоритмів**:
  - Еволюційні алгоритми (SGA, DE, NSGA-II)
  - Метаевристичні методи (Artificial Bee Colony, Grey Wolf Optimizer)
  - Детерміністичні методи локальної оптимізації (IPOPT, NLopt)

#### 3. Population
Популяція є фундаментальною структурою даних, що підтримує еволюцію рішень:

- **Структурні елементи**: зберігає колекцію кандидатів-рішень, кожне з яких складається з:
  - Вектора рішення (decision vector)
  - Відповідних значень фітнес-функції
  - Метаданих про порушення обмежень

- **Статистичний аналіз**: надає методи для отримання статистичних показників популяції:
  - `champion_x()`, `champion_f()`: найкраще знайдене рішення та його фітнес
  - `best_idx()`, `worst_idx()`: індекси найкращого та найгіршого рішення

#### 4. Archipelago (Метаструктура для масового паралелізму)
Архіпелаг є високорівневою абстракцією для підтримки масштабованих паралельних обчислень:

- **Топологічна організація**: складається з "островів" (islands), кожен з власною популяцією та алгоритмом

- **Механізми міграції**: реалізує концепцію міграції особин між островами згідно заданої топології:
  - Різні топології: Ring, Fully Connected, Free Form, Unconnected
  - Політики міграції: визначають критерії відбору мігрантів та їх впровадження в цільову популяцію

- **Асинхронне виконання**: забезпечує ефективну паралелізацію на:
  - Багатоядерних системах (через thread_island)
  - Розподілених системах (через fork_island)

### Типовий шаблон використання

Програми, побудовані на PaGMO2, дотримуються чіткого шаблону взаємодії компонентів:

```cpp
#include <pagmo/problem.hpp>
#include <pagmo/algorithm.hpp>
#include <pagmo/population.hpp>
#include <pagmo/archipelago.hpp>

// 1. Формулювання задачі оптимізації
// Варіант A: використання вбудованої задачі
problem prob{schwefel(30)};  // 30-вимірна задача Швефеля

// Варіант B: визначення власної задачі
struct custom_problem {
    vector_double fitness(const vector_double &x) const {
        // Реалізація обчислення фітнес-функції
        return {/* значення фітнес-функції */};
    }

    std::pair<vector_double, vector_double> get_bounds() const {
        // Визначення меж пошукового простору
        return {/* вектор нижніх меж */, /* вектор верхніх меж */};
    }
};
problem prob{custom_problem{}};

// 2. Вибір та конфігурація алгоритму оптимізації
algorithm algo{sga(
    100,    // кількість поколінь
    0.9,    // ймовірність кросинговеру
    1.0,    // індекс розподілу для SBX кросинговеру
    0.02,   // ймовірність мутації
    1.0     // параметр мутації
)};

// 3. Ініціалізація та еволюція популяції
// Для послідовної оптимізації:
population pop{prob, 20};  // популяція з 20 особин
pop = algo.evolve(pop);    // еволюція популяції

// 4. Для масштабованої паралельної оптимізації:
archipelago archi{
    16u,    // кількість островів
    algo,   // алгоритм для кожного острова
    prob,   // задача для кожного острова
    20u     // розмір популяції на кожному острові
};
archi.evolve(10);      // виконання 10 ітерацій еволюції
archi.wait_check();    // синхронізація роботи островів

// 5. Аналіз результатів
auto best_island = *std::min_element(archi.begin(), archi.end(),
    [](const island &isl1, const island &isl2) {
        return isl1.get_population().champion_f()[0] <
               isl2.get_population().champion_f()[0];
    });
auto best_solution = best_island.get_population().champion_x();
auto best_fitness = best_island.get_population().champion_f();
```

### Систематизація функціональних можливостей

PaGMO2 надає ряд вбудованих компонентів для вирішення різноманітних оптимізаційних задач:

#### 1. Вбудовані задачі (problems)
- **Тестові функції класичної оптимізації**:
  - Ландшафти гладких функцій: Rosenbrock, Schwefel, Ackley
  - Мультимодальні функції: Rastrigin, Griewank, Lennard-Jones

- **Стандартні тестові набори для багатокритеріальної оптимізації**:
  - ZDT: набір тестових функцій Zitzler-Deb-Thiele (ZDT1-ZDT6)
  - DTLZ: набір масштабованих тестових функцій Deb-Thiele-Laumanns-Zitzler
  - WFG: розширений набір Walking Fish Group з керованими характеристиками

- **Тестові набори для оптимізації з обмеженнями**:
  - CEC2006: набір бенчмарків IEEE Congress on Evolutionary Computation
  - CEC2009, CEC2013, CEC2014: пізніші ітерації з більш складними характеристиками

- **Проблеми комбінаторної оптимізації**:
  - Golomb-ruler: задача оптимального розміщення міток на лінійці
  - Інші дискретні та змішані цілочисельні задачі

#### 2. Вбудовані алгоритми
- **Генетичні алгоритми**:
  - SGA: класичний генетичний алгоритм з різними операторами
  - NSGA-II: неперевершений сортувальний генетичний алгоритм II для багатокритеріальних задач
  - MOEAD: багатокритеріальна оптимізація на основі декомпозиції

- **Диференціальна еволюція та її варіанти**:
  - DE: стандартна диференціальна еволюція
  - SADE: самоадаптивна диференціальна еволюція
  - DE1220: спеціальна версія для задач з обмеженнями

- **Алгоритми рою**:
  - PSO: оптимізація роєм частинок
  - NSPSO: неперевершений рій частинок для багатокритеріальних задач

- **Біоінспіровані метаевристики**:
  - Artificial Bee Colony: алгоритм штучної бджолиної колонії
  - Grey Wolf Optimizer: оптимізація на основі поведінки зграї сірих вовків
  - Simulated Annealing: імітація відпалу для глобальної оптимізації

#### 3. Можливості розширення
PaGMO2 проектувався з урахуванням модульності та розширюваності:

- **Створення власних задач (UDP)**:
  ```cpp
  struct custom_problem {
      vector_double fitness(const vector_double &x) const;
      std::pair<vector_double, vector_double> get_bounds() const;
      // Опціональні методи для розширеної функціональності
  };
  ```

- **Реалізація власних алгоритмів (UDA)**:
  ```cpp
  struct custom_algorithm {
      population evolve(population) const;
      // Опціональні методи для додаткової функціональності
  };
  ```

- **Модифікація політик міграції**:
  - Створення власних стратегій відбору для міграції
  - Впровадження спеціалізованих політик заміщення

- **Розширення топологій архіпелагу**:
  - Проектування нестандартних схем комунікації між островами
  - Дослідження впливу топології на ефективність оптимізації

Завдяки використанню шаблонного метапрограмування та механізму "стирання типу", PaGMO2 забезпечує високу гнучкість без шкоди для продуктивності, дозволяючи користувачам впроваджувати власні розширення відповідно до специфічних вимог.

## b. Типи репродукції

Бібліотека PaGMO2 пропонує гнучку систему репродукції для еволюційних алгоритмів, що включає різноманітні механізми селекції батьків, кросинговеру та формування нащадків. Дана система характеризується високою модульністю та параметризацією, що дозволяє налаштовувати процес репродукції відповідно до специфіки конкретної задачі оптимізації.

### Механізми селекції (Selection Mechanisms)

Процеси селекції визначають, яким чином особини поточної популяції обираються для подальшого розмноження. PaGMO2 реалізує наступні механізми селекції:

#### 1. Турнірна селекція (Tournament Selection)
- **Принцип роботи**: Для кожного нащадка випадковим чином формується група з `param_s` особин, з якої обирається найкраща
- **Математична формалізація**: ймовірність вибору особини $i$ з популяції розміром $N$ при турнірі розміром $k$ становить:
  $$P(i) = \frac{\binom{i}{1}\binom{N-i}{k-1}}{\binom{N}{k}}$$
- **Переваги**: контрольований селекційний тиск через параметр розміру турніру, стійкість до проблем масштабування фітнес-функції
- **Реалізація**: метод `perform_selection()` у класі `sga`

#### 2. Усічена селекція (Truncated Selection)
- **Принцип роботи**: відбирає найкращі `param_s` особин з популяції і використовує їх багаторазово для генерації нащадків
- **Характеристики**: створює сильний селективний тиск, концентруючись виключно на найкращих рішеннях
- **Застосовність**: ефективна для швидкої конвергенції, але може призводити до передчасної втрати генетичного різноманіття

#### 3. Багатокритеріальна турнірна селекція (Multi-objective Tournament Selection)
- **Принцип роботи**: використовує концепцію домінування за Парето та скупченості для вибору батьків
- **Реалізація**: функція `mo_tournament_selection_impl()` в модулі `genetic_operators`
- **Застосування**: використовується в алгоритмах NSGA-II та NSPSO для багатокритеріальної оптимізації

### Оператори кросинговеру (Crossover Operators)

Кросинговер відповідає за комбінування генетичного матеріалу батьків для створення нащадків. PaGMO2 підтримує наступні схеми кросинговеру:

#### 1. Експоненціальний кросинговер (Exponential Crossover)
- **Алгоритм**: починаючи з випадкової позиції, послідовно копіює гени від другого батька з ймовірністю `cr` до поки не зупиниться
- **Математичне сподівання**: кількість генів L, що будуть обмінені, має геометричний розподіл:
  $$E[L] = \frac{1}{1-cr}$$
- **Походження**: адаптований з алгоритму диференціальної еволюції
- **Реалізація**: метод `perform_crossover()` у класі `sga` з параметром `m_crossover = detail::sga_crossover::EXPONENTIAL`

#### 2. Біноміальний кросинговер (Binomial Crossover)
- **Принцип роботи**: кожен ген нащадка незалежно обирається від першого або другого батька з ймовірністю `cr`
- **Статистична характеристика**: кількість обмінюваних генів має біноміальний розподіл з параметрами:
  $$L \sim B(n, cr)$$
  де $n$ - розмірність задачі
- **Переваги**: більш однорідний розподіл точок розриву хромосоми порівняно з експоненціальним кросинговером

#### 3. Одноточковий кросинговер (Single Point Crossover)
- **Механізм**: обирається випадкова точка перетину, до якої гени беруться від першого батька, після неї — від другого
- **Характеристики**: зберігає цілісні блоки генів (низька схильність до розривання епістазису)
- **Формальний опис**: Для точки перетину $k$ та батьківських хромосом $P_1$ і $P_2$ нащадок $O$ формується як:
  $$O[i] = \begin{cases}
    P_1[i], & \text{якщо } i < k \\
    P_2[i], & \text{якщо } i \geq k
  \end{cases}$$

#### 4. Імітаційний бінарний кросинговер (Simulated Binary Crossover, SBX)
- **Концепція**: моделює дію бінарного кросинговеру на дійсні значення, зберігаючи центрованість та дисперсію
- **Параметризація**: використовує індекс розподілу `eta_c` для контролю дисперсії нащадків — вищі значення призводять до нащадків, ближчих до батьків
- **Математична модель**: використовує наступний розподіл для коефіцієнта розширення $\beta$:
  $$P(\beta) = \begin{cases}
    0.5(\eta_c+1)\beta^{\eta_c}, & \text{якщо } \beta \leq 1 \\
    0.5(\eta_c+1)\frac{1}{\beta^{\eta_c+2}}, & \text{інакше}
  \end{cases}$$
- **Джерело**: адаптований з алгоритму NSGA-II, реалізований у функції `sbx_crossover()` в модулі `utils/genetic_operators`

### Комплексна репродуктивна стратегія в SGA

В простому генетичному алгоритмі (SGA) PaGMO2 реалізує цілісну стратегію репродукції, що складається з наступних етапів:

1. **Селекція**: створення нової популяції розміром $N$ шляхом вибору особин з існуючої популяції (з можливістю повторення)
2. **Кросинговер**: створення популяції нащадків шляхом застосування обраного оператора кросинговеру до батьківських пар
3. **Мутація**: застосування оператора мутації до популяції нащадків
4. **Оцінка**: обчислення значень фітнес-функції для нових особин
5. **Заміщення**: об'єднання батьківської популяції та нащадків, відбір найкращих $N$ особин для наступного покоління

Така схема забезпечує збалансований пошук у просторі рішень, комбінуючи експлуатацію існуючих рішень через селекцію з дослідженням нових областей через кросинговер та мутацію.

### Розширюваність системи репродукції

Архітектура PaGMO2 забезпечує можливість розширення репродуктивних механізмів через:

1. **Впровадження нових UDA**: створення власних алгоритмів з нестандартними репродуктивними схемами
   ```cpp
   struct custom_ga {
       population evolve(population pop) const {
           // Реалізація власної схеми репродукції
           return evolved_pop;
       }
   };
   ```

2. **Модифікація існуючих операторів**: налаштування параметрів селекції, кросинговеру та мутації
   ```cpp
   algorithm algo{sga(
       100,                        // генерації
       0.95,                       // ймовірність кросинговеру
       10.0,                       // індекс розподілу SBX
       0.01,                       // ймовірність мутації
       50.0,                       // параметр поліноміальної мутації
       5,                          // розмір турніру або кількість елітних особин
       "sbx",                      // тип кросинговеру
       "polynomial",               // тип мутації
       "tournament"                // метод селекції
   )};
   ```

3. **Інтеграція з політиками міграції**: взаємодія з механізмами міграції в архіпелазі для глобального обміну генетичною інформацією

PaGMO2 надає ретельно збалансовану систему репродукції, що поєднує класичні та сучасні підходи до еволюційної оптимізації, підтримуючи як класичні генетичні алгоритми, так і сучасні багатокритеріальні методи.

## c. Умови зупинки роботи алгоритму

Бібліотека PaGMO2 імплементує різноманітні критерії завершення роботи алгоритмів оптимізації, які можна систематизувати у декілька категорій. Дані умови зупинки характеризуються спільними патернами реалізації, водночас маючи специфічні особливості для різних типів алгоритмів.

### Категорії умов зупинки

#### 1. Обмеження на кількість ітерацій

**Кількість поколінь (Number of Generations)**
- **Застосування**: основний критерій зупинки для більшості еволюційних алгоритмів
- **Параметризація**: через параметр `gen` у конструкторах алгоритмів
- **Реалізація**: параметр зберігається як член класу (зазвичай `m_gen`); у методі `evolve()` відбувається інкремент лічильника поточного покоління до досягнення заданого значення
- **Приклади**:
  ```cpp
  // SGA з 500 поколіннями
  algorithm algo{sga(500, 0.9, 1.0, 0.02, 1.0)};

  // NSGA-II з 100 поколіннями
  algorithm algo{nsga2(100)};
  ```

**Максимальна кількість обчислень функції (Maximum Function Evaluations)**
- **Застосування**: використовується в алгоритмах, де поняття покоління не є виразним, або як додатковий критерій
- **Параметризація**: через параметр `max_fevals` у конструкторах відповідних алгоритмів
- **Приклади**:
  ```cpp
  // Compass Search з обмеженням на 10000 обчислень функції
  algorithm algo{compass_search(10000)};
  ```

#### 2. Критерії збіжності (Convergence Criteria)

**Толерантність за значенням фітнес-функції (Fitness Tolerance)**
- **Принцип**: алгоритм зупиняється, коли різниця між найкращим та найгіршим значенням фітнес-функції в популяції стає меншою за заданий поріг
- **Параметризація**: через параметр `ftol` у конструкторі алгоритму
- **Математична формалізація**: зупинка відбувається, коли $|f_{\text{best}} - f_{\text{worst}}| < \varepsilon_f$
- **Застосування**: реалізовано в алгоритмі диференціальної еволюції (DE)
- **Код**:
  ```cpp
  // Дифференціальна еволюція з толерантністю за значенням фітнес-функції 1e-6
  algorithm algo{de(100, 0.8, 0.9, 2, 1e-6, 1e-6)};
  ```

**Толерантність за вектором рішення (Decision Vector Tolerance)**
- **Принцип**: алгоритм зупиняється, коли різниця між найкращим та найгіршим векторами рішень у популяції стає меншою за заданий поріг
- **Параметризація**: через параметр `xtol` у конструкторі алгоритму
- **Математична формалізація**: зупинка відбувається, коли $\|x_{\text{best}} - x_{\text{worst}}\|_{\infty} < \varepsilon_x$
- **Застосування**: реалізовано в алгоритмі диференціальної еволюції (DE)
- **Код**:
  ```cpp
  // Диференціальна еволюція з толерантністю за вектором рішення 1e-6
  algorithm algo{de(100, 0.8, 0.9, 2, 1e-6, 1e-6)};
  ```

#### 3. Спеціалізовані критерії зупинки

**Критерій діапазону пошуку (Range-based Termination)**
- **Застосування**: використовується в алгоритмі Compass Search
- **Принцип**: алгоритм зупиняється, коли діапазон пошуку стає меншим за заданий поріг
- **Параметризація**: через параметри `start_range`, `stop_range` та `reduction_coeff`
- **Реалізація**: Діапазон пошуку зменшується при невдалих пробах за формулою $r_{i+1} = r_i \cdot c_r$, де $c_r$ - коефіцієнт зменшення

**Критерій температури (Temperature-based Termination)**
- **Застосування**: використовується в алгоритмі імітації відпалу (Simulated Annealing)
- **Принцип**: алгоритм зупиняється, коли температура досягає заданого кінцевого значення
- **Параметризація**: через параметри `Ts` (початкова температура), `Tf` (кінцева температура) та `n_T_adj` (кількість корекцій температури)
- **Реалізація**: температура зменшується за певним законом (зазвичай геометрична прогресія) після визначеної кількості ітерацій
- **Код**:
  ```cpp
  // Імітація відпалу з початковою температурою 10 та кінцевою 0.01
  algorithm algo{simulated_annealing(10.0, 0.01, 10, 10, 100, 0.01)};
  ```

### Логування прогресу та дострокова зупинка

PaGMO2 надає механізми для відстеження прогресу оптимізації через систему логування та можливість налаштування рівня деталізації виводу:

**Система логування**
- **Параметризація**: через метод `set_verbosity(unsigned level)`, доступний у всіх алгоритмах
- **Функціональність**: збирає інформацію про процес оптимізації (покоління, кількість обчислень функції, найкраще значення, метрики конвергенції)
- **Доступ до логу**: метод `get_log()` повертає накопичену інформацію про процес оптимізації
- **Приклад запису логу** (DE):
  - Gen: номер покоління
  - Fevals: кількість обчислень функції
  - Best: найкраще значення фітнес-функції
  - dx: метрика різниці між векторами рішень
  - df: метрика різниці між значеннями фітнес-функції

### Модель використання критеріїв зупинки

Умови зупинки в PaGMO2 реалізуються за наступною схемою:

1. **Параметризація**: критерії зупинки визначаються при створенні об'єкта алгоритму через його конструктор
2. **Збереження стану**: параметри зберігаються як члени класу алгоритму
3. **Перевірка умов**: у методі `evolve()` відбувається перевірка умов зупинки після кожної ітерації
4. **Логування**: при досягненні умов зупинки, кінцеві результати додаються до логу алгоритму

Даний підхід дозволяє ефективно контролювати обчислювальні ресурси та забезпечувати баланс між якістю знайдених рішень та часом виконання алгоритму, що є особливо важливим для задач високої розмірності та обчислювально затратних функцій оцінки.

## d. Способи кодування розв'язків

Бібліотека PaGMO2 застосовує уніфікований підхід до представлення розв'язків оптимізаційних задач, одночасно забезпечуючи гнучкість та ефективність обробки різних типів змінних. Система кодування розв'язків характеризується єдиним базовим форматом з додатковими механізмами для специфічних типів даних.

### Базове представлення розв'язків

#### Основна структура представлення

PaGMO2 використовує єдиний тип даних для кодування всіх розв'язків:

```cpp
typedef std::vector<double> vector_double;
```

Цей тип є основним представленням будь-якого розв'язку незалежно від характеру задачі:
- **Одновимірність**: всі розв'язки є одновимірними векторами дійсних чисел
- **Послідовність значень**: елементи вектора відповідають значенням змінних рішення
- **Уніфікований інтерфейс**: всі алгоритми працюють з цим єдиним форматом даних

#### Взаємодія між компонентами системи

Базова уніфікація інтерфейсу через `vector_double` забезпечує чітку взаємодію між різними компонентами системи:

- **Метод fitness()**: приймає `vector_double` як аргумент і повертає `vector_double` як результат
- **Обмін даними**: єдиний формат забезпечує безперешкодний обмін даними між різними алгоритмами та задачами
- **Серіалізація**: спрощене збереження та відновлення стану популяцій та рішень

### Підтримка різних типів змінних

Хоча базове представлення використовує дійсні числа, PaGMO2 ефективно підтримує різні типи змінних через спеціалізовані механізми:

#### Поширені способи кодування розв'язків в еволюційних алгоритмах

Еволюційні алгоритми використовують різні способи кодування розв'язків залежно від природи задачі оптимізації:

##### 1. Бінарне кодування (Binary Encoding)
- **Опис**: представлення розв'язків у вигляді бітових рядків, де кожен біт приймає значення 0 або 1
- **Переваги**: 
  - Простота реалізації операторів кросинговеру та мутації
  - Відповідність біологічним аналогіям генетичних алгоритмів
  - Природність для комбінаторних та дискретних задач
- **Недоліки**: 
  - Низька ефективність для задач з дійсними змінними (потребує декодування)
  - Проблема фальшивих точок (Hamming cliffs) при кодуванні неперервних змінних
- **Статус в PaGMO2**: не реалізовано на рівні бібліотеки, користувач має самостійно імплементувати через власні задачі (UDP)

##### 2. Код Грея (Gray Code)
- **Опис**: модифікація бінарного кодування, де сусідні значення відрізняються лише одним бітом
- **Переваги**: 
  - Усуває проблему фальшивих точок, властиву для стандартного бінарного кодування
  - Забезпечує більшу локальність при пошуку - малі зміни в просторі рішень відповідають малим змінам у закодованому представленні
- **Математична формалізація**: перетворення бінарного числа в код Грея:
  ```
  G₀ = B₀
  G_i = B_i ⊕ B_{i-1}, для i > 0
  ```
  де ⊕ — операція XOR
- **Статус в PaGMO2**: не реалізовано на рівні бібліотеки, користувач має імплементувати в рамках своєї UDP

##### 3. Дійсне кодування (Real-valued Encoding)
- **Опис**: безпосереднє представлення розв'язків як векторів дійсних чисел
- **Переваги**: 
  - Природність для задач з неперервними змінними
  - Відсутність потреби в декодуванні/кодуванні
  - Можливість використання спеціалізованих операторів (наприклад, SBX)
- **Статус в PaGMO2**: основний спосіб кодування, реалізований через `vector_double`

##### 4. Цілочисельне кодування (Integer Encoding)
- **Опис**: представлення розв'язків як послідовностей цілих чисел
- **Застосування**: дискретні задачі оптимізації, комбінаторні задачі, задачі маршрутизації
- **Статус в PaGMO2**: реалізується через округлення дійсних чисел у рамках обчислення фітнес-функції

##### 5. Перестановочне кодування (Permutation Encoding)
- **Опис**: представлення розв'язків як перестановок елементів
- **Застосування**: задачі комівояжера, задачі про призначення, задачі впорядкування
- **Статус в PaGMO2**: не реалізовано на рівні бібліотеки, користувач має імплементувати через UDP

##### 6. Деревовидне кодування (Tree Encoding)
- **Опис**: представлення розв'язків у вигляді деревовидних структур
- **Застосування**: символьна регресія, автоматичне програмування, генетичне програмування
- **Статус в PaGMO2**: не підтримується на рівні базової бібліотеки

#### Реалізація нестандартних кодувань в PaGMO2

Хоча PaGMO2 безпосередньо підтримує лише дійсночисельне кодування, розробникам доступні механізми для впровадження інших способів кодування через користувацькі задачі (UDP):

1. **Кодування/декодування в методах фітнес-функції**:
   ```cpp
   vector_double fitness(const vector_double &x) const {
       // Перетворення vector_double у бажане представлення
       auto encoded = encode(x);
       // Обчислення фітнес-функції
       auto result = evaluate(encoded);
       return result;
   }
   ```

2. **Налаштування параметрів генетичних операторів**:
   Для задач, що потребують специфічних операторів (наприклад, для перестановочного кодування), користувачі можуть створити власний метод `evolve()`:
   ```cpp
   struct custom_permutation_ga {
       population evolve(population pop) const {
           // Реалізація специфічних операторів для перестановок
           return evolved_pop;
       }
   };
   ```

3. **Інтеграція з зовнішніми бібліотеками**:
   Для складних кодувань (наприклад, деревовидного) можлива інтеграція з спеціалізованими бібліотеками:
   ```cpp
   struct genetic_programming_udp {
       // Інтеграція з зовнішньою GP бібліотекою
       vector_double fitness(const vector_double &x) const {
           // Перетворення vector_double в структуру дерева
           // та обчислення фітнес-функції
       }
   };
   ```

### Практичні аспекти реалізації різних кодувань

Реалізація нестандартних кодувань у PaGMO2 вимагає чіткого розуміння механізмів взаємодії між компонентами системи:

1. **Обмеження за значеннями** (`get_bounds()`):
   - Визначають допустимий діапазон значень для кожної змінної
   - Для бінарного кодування можна використовувати границі [0, 1] з подальшим округленням

2. **Інтерпретація у фітнес-функції** (`fitness()`):
   - Перетворення внутрішнього представлення в необхідний формат (бінарний, код Грея, перестановка)
   - Виконання обчислень з урахуванням специфіки представлення
   
3. **Модифікація генетичних операторів**:
   - Забезпечення коректності операцій з урахуванням специфіки кодування
   - Імплементація спеціалізованих операторів мутації та кросинговеру

Незважаючи на відсутність вбудованої підтримки різноманітних кодувань, архітектура PaGMO2 забезпечує високу гнучкість, дозволяючи користувачам ефективно впроваджувати власні схеми кодування для специфічних задач оптимізації.

#### 1. Неперервні змінні

- **Пряме представлення**: зберігаються безпосередньо як значення з плаваючою точкою
- **Повна сумісність**: всі оператори та алгоритми природно працюють з неперервними змінними
- **Межі значень**: визначаються через `get_bounds()`, що повертає пару векторів нижніх та верхніх меж

#### 2. Цілочисельні змінні

PaGMO2 використовує спеціальну схему для роботи з цілочисельними змінними:

- **Позиціонування**: цілочисельні змінні повинні розташовуватися в кінці вектора рішення
- **Ідентифікація**: метод `get_nix()` задачі повертає кількість цілочисельних змінних
- **Внутрішнє представлення**: зберігаються як дійсні числа, але з гарантією цілочисельних значень
- **Адаптація операторів**: генетичні оператори (кросинговер, мутація) адаптуються для збереження цілочисельних обмежень

**Приклад оголошення цілочисельних змінних**:
```cpp
struct minlp_problem {
    // ...
    vector_double::size_type get_nix() const {
        return m_integer_dim; // Кількість цілочисельних змінних
    }
    // ...
};
```

#### 3. Змішані задачі (MINLP)

PaGMO2 ефективно підтримує змішані задачі нелінійного програмування (Mixed Integer Non-Linear Programming):

- **Структура вектора**: \(x = [x_1, x_2, ..., x_{n-m}, x_{n-m+1}, ..., x_n]\), де перші \(n-m\) змінних є неперервними, а останні \(m\) — цілочисельними
- **Приклад задачі**: клас `minlp_rastrigin` демонструє реалізацію змішаної задачі
- **Конструювання**:
  ```cpp
  minlp_rastrigin(unsigned dim_c = 1u, unsigned dim_i = 1u);
  ```
  де `dim_c` — кількість неперервних змінних, а `dim_i` — кількість цілочисельних змінних

### Адаптація генетичних операторів

Оператори генетичних алгоритмів модифікуються для коректної роботи з різними типами змінних:

#### 1. Кросинговер

- **Неперервні змінні**: застосовуються стандартні оператори (експоненціальний, біноміальний, одноточковий, SBX)
- **Цілочисельні змінні**: використовуються спеціалізовані варіанти операторів або дискретизація результату
- **Змішані вектори**: різні частини вектора можуть оброблятися різними операторами

#### 2. Мутація

- **Неперервні змінні**: гаусівська, рівномірна або поліноміальна мутація
- **Цілочисельні змінні**: спеціалізовані оператори з округленням або дискретизацією
- **Приклад адаптації**:
  ```cpp
  // Приклад адаптації мутації для цілочисельних змінних
  for (decltype(dim_i) i = 0u; i < dim_i; ++i) {
      auto idx = dim_c + i;
      auto mutated_value = /* мутація */;
      X[idx] = std::round(mutated_value); // Округлення до цілого числа
  }
  ```

### Реалізація користувацьких схем кодування

PaGMO2 дозволяє реалізувати власні схеми кодування через механізм абстракції задачі:

#### 1. Внутрішнє перетворення

- **Приховане кодування**: користувач може визначити внутрішнє представлення розв'язку, відмінне від `vector_double`
- **Механізм перетворення**: реалізувати методи перетворення між внутрішнім представленням та `vector_double`
- **Інкапсуляція**: зберегти всю логіку кодування/декодування всередині класу задачі

#### 2. Схема реалізації

```cpp
struct custom_encoded_problem {
    // Внутрішнє представлення
    struct internal_solution {
        // Специфічне представлення (наприклад, матриця, граф, дерево)
    };

    // Перетворення з vector_double у внутрішнє представлення
    internal_solution decode(const vector_double &x) const {
        // Логіка декодування
        return internal_solution{/*...*/};
    }

    // Перетворення з внутрішнього представлення в vector_double
    vector_double encode(const internal_solution &sol) const {
        // Логіка кодування
        return vector_double{/*...*/};
    }

    // Основний метод фітнес-функції
    vector_double fitness(const vector_double &x) const {
        // Декодуємо у внутрішнє представлення
        auto internal = decode(x);

        // Обчислюємо фітнес-функцію для внутрішнього представлення
        // ...

        // Повертаємо результат
        return {fitness_value};
    }

    // Інші необхідні методи...
};
```

#### 3. Обмеження

Варто зазначити існуючі обмеження при реалізації користувацьких схем кодування:

- **Зовнішній інтерфейс**: незалежно від внутрішньої схеми, зовнішній інтерфейс повинен працювати з `vector_double`
- **Сумісність з операторами**: користувацькі схеми повинні забезпечувати коректну роботу зі стандартними генетичними операторами або потребують нових UDA
- **Обмеження розмірності**: слід забезпечити узгодженість між розмірністю внутрішнього представлення та вектора `vector_double`

Завдяки такому підходу, PaGMO2 надає уніфікований інтерфейс для роботи з різноманітними типами оптимізаційних задач, одночасно забезпечуючи достатню гнучкість для специфічних випадків.

## e. Функція пристосованості, підтримувані модифікації

Функція пристосованості (fitness function) є центральним компонентом бібліотеки PaGMO2, що визначає критерії оптимальності розв'язку та забезпечує оцінку його якості. Реалізація функцій пристосованості в PaGMO2 характеризується глибокою інтеграцією з іншими компонентами системи та підтримкою широкого спектру модифікацій для різних типів оптимізаційних задач.

### Структура та організація функцій пристосованості

#### Формальна специфікація

Базовий інтерфейс функції пристосованості визначається в кожному класі задачі через метод:

```cpp
vector_double fitness(const vector_double &x) const;
```

Цей метод приймає вектор рішення `x` і повертає вектор, що містить значення цільових функцій, а також, у випадку обмежень, значення функцій-обмежень.

#### Структура вектора пристосованості

Вектор, що повертається методом `fitness()`, має наступну структуру:

```
[f₁, f₂, ..., fₙ, g₁, g₂, ..., gₘ, h₁, h₂, ..., hₚ]
```

де:
- `f₁, f₂, ..., fₙ` - значення цільових функцій (для однокритеріальних задач n = 1)
- `g₁, g₂, ..., gₘ` - значення обмежень-рівностей (g_i = 0 для задоволення обмеження)
- `h₁, h₂, ..., hₚ` - значення обмежень-нерівностей (h_i ≤ 0 для задоволення обмеження)

#### Додаткові методи специфікації

Для повної специфікації функції пристосованості клас задачі може реалізувати ряд додаткових методів:

```cpp
// Кількість цільових функцій (за замовчуванням 1)
vector_double::size_type get_nobj() const { return 1u; }

// Кількість обмежень-рівностей
vector_double::size_type get_nec() const { return m_nec; }

// Кількість обмежень-нерівностей
vector_double::size_type get_nic() const { return m_nic; }

// Допуски для обмежень (опціонально)
vector_double get_c_tol() const { return m_c_tol; }
```

### Підтримка багатокритеріальної оптимізації

PaGMO2 надає повну підтримку для задач з декількома критеріями оптимальності:

#### 1. Визначення кількості цільових функцій

```cpp
struct multi_objective_problem {
    // ...
    vector_double::size_type get_nobj() const {
        return 3; // Задача з трьома критеріями
    }
    // ...
};
```

#### 2. Утиліти для багатокритеріальних задач

Модуль `multi_objective.hpp` реалізує численні функції для роботи з багатокритеріальними задачами:

- **Парето-домінування**: функція `pareto_dominance(v1, v2)` визначає, чи домінує вектор v1 над v2
- **Недоміновані фронти**: функція `fast_non_dominated_sorting()` реалізує алгоритм NSGA-II для сортування популяції за фронтами
- **Метрика скупченості**: функція `crowding_distance()` обчислює метрику різноманітності для підтримки різноманіття у популяції
- **Сортування популяції**: функція `sort_population_mo()` виконує повне сортування популяції за Парето-оптимальністю та скупченістю

#### 3. Декомпозиція багатокритеріальних задач

PaGMO2 підтримує методи декомпозиції для багатокритеріальних задач:

```cpp
// Генерація вагових векторів для декомпозиції
auto weights = decomposition_weights(3u, 10u, "low discrepancy", r_engine);

// Декомпозиція багатокритеріальної задачі у скалярну
auto scalar_fitness = decompose_objectives(multi_obj_fitness, weight_vector, reference_point, decomposition_method);
```

### Моделювання та обробка обмежень

PaGMO2 надає широкі можливості для роботи з обмеженнями в оптимізаційних задачах:

#### 1. Визначення обмежень

Обмеження визначаються як частина вектора, що повертається функцією `fitness()`:

```cpp
vector_double fitness(const vector_double &x) const {
    // Обчислення значення цільової функції
    double f = /* ... */;

    // Обчислення обмеження-рівності
    double g = /* ... */;  // Має бути 0 для задоволення

    // Обчислення обмеження-нерівності
    double h = /* ... */;  // Має бути <= 0 для задоволення

    return {f, g, h};
}
```

#### 2. Методи обробки обмежень

Модуль `constrained.hpp` містить утиліти для роботи з обмеженнями:

- **Перевірка задоволення обмежень**: функції `test_eq_constraints()` та `test_ineq_constraints()`
- **Порівняння розв'язків з обмеженнями**: функція `compare_fc()` порівнює два вектори пристосованості з урахуванням обмежень
- **Сортування популяції**: функція `sort_population_con()` сортує популяцію з урахуванням обмежень

#### 3. Штрафні функції та альтернативні підходи

PaGMO2 підтримує кілька підходів до обробки обмежень:

- **Пряме порівняння**: безпосереднє порівняння розв'язків за їх допустимістю та значенням фітнес-функції
- **Допуски обмежень**: можливість встановлення допусків через метод `set_c_tol()` або `problem::set_c_tol()`
- **Зняття обмежень**: клас `unconstrain` дозволяє перетворювати задачу з обмеженнями в необмежену через штрафні функції

Приклад реалізації штрафної функції через обгортку `unconstrain`:

```cpp
// Створення необмеженої версії задачі з методом штрафів
problem prob{unconstrain{original_problem, "weighted"}};
```

Доступні методи зняття обмежень:
- `"weighted"`: штрафна функція з ваговими коефіцієнтами
- `"death"`: штраф "смертю" - неприпустимі розв'язки отримують дуже погане значення фітнес-функції
- `"kuri"`: метод Курі для багатокритеріальних задач з обмеженнями

### Спеціалізовані можливості та розширення

#### 1. Пакетна оцінка фітнес-функції

PaGMO2 підтримує ефективну оцінку фітнес-функції для груп розв'язків через механізм пакетних обчислювачів (Batch Fitness Evaluators, BFE):

```cpp
// Визначення пакетного обчислювача
problem p{/* ... */};
bfe b{thread_bfe{}};  // Паралельний обчислювач на основі потоків

// Пакетне обчислення фітнес-функції
std::vector<vector_double> xs = /* ... */;
auto fitnesses = p.batch_fitness(xs, b);
```

#### 2. Стохастичні функції пристосованості

Для задач зі стохастичною поведінкою (шум, невизначеність) PaGMO2 надає спеціальні механізми:

```cpp
struct stochastic_problem {
    // ...
    // Метод для встановлення насіння генератора випадкових чисел
    void set_seed(unsigned seed) {
        m_seed = seed;
        m_engine.seed(seed);
    }
    // ...
};
```

#### 3. Підтримка градієнтів та гессіанів

Для задач, що потребують диференціювання, можна реалізувати методи обчислення градієнтів та гессіанів:

```cpp
// Обчислення градієнта
vector_double gradient(const vector_double &x) const;

// Обчислення гессіана
std::vector<vector_double> hessians(const vector_double &x) const;

// Визначення структури розрідженості гессіана
std::vector<sparsity_pattern> hessians_sparsity() const;
```

### Реалізація користувацьких функцій пристосованості

Створення власної функції пристосованості в PaGMO2 здійснюється через визначення класу задачі з необхідними методами:

```cpp
struct my_problem {
    // Обов'язкові методи
    vector_double fitness(const vector_double &x) const {
        // Обчислення фітнес-функції
        double f = /* ... */;
        return {f};
    }

    std::pair<vector_double, vector_double> get_bounds() const {
        // Повернення меж змінних
        return {{/* нижні межі */}, {/* верхні межі */}};
    }

    // Опціональні методи для розширеної функціональності
    vector_double::size_type get_nobj() const { return /* к-ть цільових функцій */; }
    vector_double::size_type get_nec() const { return /* к-ть обмежень-рівностей */; }
    vector_double::size_type get_nic() const { return /* к-ть обмежень-нерівностей */; }
    vector_double::size_type get_nix() const { return /* к-ть цілочисельних змінних */; }
};
```

Система функцій пристосованості в PaGMO2 надає потужний та гнучкий інструментарій для моделювання широкого спектру оптимізаційних задач: від простих однокритеріальних необмежених до комплексних багатокритеріальних задач з обмеженнями та стохастичністю.

## f. Оператори відбору, можливості їх налаштування

Оператори відбору є критичними компонентами еволюційної оптимізації, що визначають, які особини отримують можливість передавати свої гени наступному поколінню. PaGMO2 реалізує широкий спектр операторів відбору з різним рівнем складності та налаштовуваності, які можна адаптувати до специфіки конкретної оптимізаційної задачі.

### Основні методи відбору

#### 1. Турнірний відбір (Tournament Selection)

Турнірний відбір є найпоширенішим механізмом відбору в генетичних алгоритмах PaGMO2:

- **Принцип роботи**: формує випадкові групи (турніри) з `param_s` особин і обирає найкращу особину з кожної групи
- **Математична модель**: ймовірність вибору особини з рангом $i$ у популяції розміром $N$ з турніром розміром $k$ дорівнює:
  $P(i) = \frac{(i)^{k} - (i-1)^{k}}{N^{k}}$

- **Імплементація**: метод `sga::perform_selection()` з параметром `m_selection = detail::sga_selection::TOURNAMENT`
- **Особливості**:
  - Параметр `param_s` контролює селективний тиск (більший розмір турніру — сильніший тиск)
  - Стійкість до проблем масштабування фітнес-значень
  - Балансує між дослідженням та експлуатацією рішень

```cpp
// Налаштування турнірного відбору в SGA з розміром турніру 3
algorithm algo{sga(100, 0.9, 1.0, 0.1, 1.0, 3, "exponential", "polynomial", "tournament")};
```

#### 2. Усічений відбір (Truncated Selection)

Усічений відбір реалізує елітистський підхід, концентруючись на найкращих особинах популяції:

- **Принцип роботи**: відбирає топ-`param_s` найкращих особин з популяції і використовує їх для створення всіх нащадків
- **Характеристики**:
  - Висока швидкість збіжності до локальних оптимумів
  - Схильність до передчасної конвергенції
  - Значно знижує генетичне різноманіття

```cpp
// Усічений відбір в SGA з топ-10 особин
algorithm algo{sga(100, 0.9, 1.0, 0.1, 1.0, 10, "exponential", "polynomial", "truncated")};
```

#### 3. Багатокритеріальний турнірний відбір

Для багатокритеріальних задач реалізовано спеціалізований турнірний відбір, що враховує недомінованість та скупченість розв'язків:

- **Принцип роботи**: порівнює дві випадково обрані особини за такими критеріями:
  - Ранг недомінування (нижчий ранг має перевагу)
  - Скупченість (вища скупченість має перевагу при однаковому рангу)
  - Випадковий вибір при однакових значеннях

- **Реалізація**: функція `detail::mo_tournament_selection_impl()` у модулі `genetic_operators`
- **Застосування**: використовується в алгоритмах NSGA-II та NSPSO

```cpp
// Приклад коду, що демонструє логіку багатокритеріального турнірного відбору:
vector_double::size_type idx_a = /* ... */;
vector_double::size_type idx_b = /* ... */;

// Порівняння за рангом Парето
if (pareto_rank[idx_a] < pareto_rank[idx_b]) {
    return idx_a;  // a має кращий ранг
} else if (pareto_rank[idx_a] > pareto_rank[idx_b]) {
    return idx_b;  // b має кращий ранг
} else {
    // Однаковий ранг, порівнюємо за скупченістю
    if (crowding_distance[idx_a] > crowding_distance[idx_b]) {
        return idx_a;  // a має більшу скупченість
    } else if (crowding_distance[idx_a] < crowding_distance[idx_b]) {
        return idx_b;  // b має більшу скупченість
    } else {
        // Рівнозначні особини, випадковий вибір
        return (drng(m_e) < 0.5) ? idx_a : idx_b;
    }
}
```

### Спеціалізовані механізми відбору

#### 1. Селективні політики для міграції (Selection Policies)

PaGMO2 реалізує механізми відбору особин для міграції між островами в архіпелазі:

- **`select_best`**: вибирає найкращі особини для міграції
  - Параметризується абсолютною кількістю або відносною часткою мігрантів
  - Адаптується до типу задачі (однокритеріальна/багатокритеріальна, з обмеженнями/без)

```cpp
// Політика відбору 5% найкращих особин для міграції
s_policy select_policy{select_best{0.05}};

// Політика відбору точно 3 найкращих особин
s_policy select_policy{select_best{3}};
```

#### 2. Декомпозиційний відбір

Для багатокритеріальних алгоритмів на основі декомпозиції (MOEAD) реалізовано спеціальний механізм відбору:

- **Принцип роботи**: розкладає багатокритеріальну задачу на множину скалярних підзадач
- **Методи скаляризації**:
  - Зважена сума (Weighted Sum)
  - Метод Чебишева (Tchebycheff)
  - Граничний метод (Boundary Intersection)
- **Особливості**:
  - Ваговий вектор визначає "напрямок" оптимізації
  - Створення різноманітних вагових векторів забезпечує рівномірне наближення до Парето-фронту

```cpp
// Створення підзадач через декомпозицію з методом Чебишева
auto weights = decomposition_weights(3u, 100u, "low discrepancy", r_engine);
auto scalar_fitness = decompose_objectives(fitness_vector, weights[i], reference_point, "tchebycheff");
```

### Обробка обмежень при відборі

PaGMO2 підтримує кілька стратегій урахування обмежень при відборі:

1. **Пряме порівняння з пріоритетом допустимості**:
   - Допустимі розв'язки завжди мають перевагу над недопустимими
   - Серед допустимих розв'язків вибирається кращий за значенням фітнес-функції
   - Серед недопустимих - з меншим порушенням обмежень

2. **Сортування з урахуванням обмежень**:
   - Функція `sort_population_con()` забезпечує сортування популяції з урахуванням обмежень
   - Використовує вектор допусків `tol` для обмежень

```cpp
// Сортування популяції з урахуванням обмежень з допуском 1e-5
auto sorted_indices = sort_population_con(fitnesses, 1u, 1e-5);
```

### Можливості налаштування операторів відбору

#### 1. Параметрична конфігурація

Основні параметри налаштування операторів відбору:

- **Розмір турніру**: контролює селективний тиск у турнірному відборі
- **Порогове значення**: визначає кількість елітних особин у усіченому відборі
- **Міграційна ставка**: визначає кількість мігрантів у політиках відбору для архіпелагу

#### 2. Функціональна адаптація

Оператори відбору в PaGMO2 автоматично адаптуються до різних типів задач:

- **Однокритеріальні/багатокритеріальні задачі**: відповідна стратегія порівняння
- **Задачі з обмеженнями**: урахування порушень обмежень з відповідними допусками
- **Змішані цілочисельні задачі**: прозора підтримка різних типів змінних

### Реалізація користувацьких операторів відбору

PaGMO2 надає кілька механізмів для створення власних операторів відбору:

#### 1. Користувацькі політики відбору (UDSP)

Для реалізації власної політики відбору для міграції необхідно створити клас з методом:

```cpp
struct custom_selection_policy {
    individuals_group_t select(const individuals_group_t &inds,
                             const vector_double::size_type &nx,
                             const vector_double::size_type &nix,
                             const vector_double::size_type &nobj,
                             const vector_double::size_type &nec,
                             const vector_double::size_type &nic,
                             const vector_double &tol) const {
        // Реалізація логіки відбору

        // Повернення відібраних особин
        return selected_inds;
    }

    // Опціональні методи
    std::string get_name() const {
        return "Custom Selection Policy";
    }

    std::string get_extra_info() const {
        return "Додаткова інформація про політику відбору";
    }
};

// Використання:
s_policy select_pol{custom_selection_policy{}};
```

#### 2. Інтеграція в користувацькі алгоритми

Для створення алгоритму з власним механізмом відбору:

```cpp
struct custom_evolutionary_algorithm {
    population evolve(population pop) const {
        // ...

        // Реалізація власного механізму відбору
        std::vector<vector_double::size_type> selected_idx;
        for (vector_double::size_type i = 0; i < pop.size(); ++i) {
            // Логіка відбору, наприклад, на основі розподілу ймовірностей
            if (/* ... */) {
                selected_idx.push_back(i);
            }
        }

        // Використання відібраних індексів
        // ...

        return pop;
    }

    // Інші необхідні методи...
};
```

#### 3. Розширення існуючих механізмів

Можливо розширювати існуючі механізми відбору через наслідування або композицію:

```cpp
struct tournament_with_elitism : public sga {
    // Розширена версія турнірного відбору з елітизмом
    // ...
};
```

Система операторів відбору в PaGMO2 забезпечує гнучкий та ефективний механізм для направлення еволюційного пошуку. Можливість налаштування параметрів та адаптації до різних типів задач, а також відкритий інтерфейс для користувацьких реалізацій, робить цю систему потужним інструментом для еволюційної оптимізації.

## g. Оператори кросинговеру, можливості їх налаштування

Оператори кросинговеру в PaGMO2 відіграють ключову роль у процесі рекомбінації генетичного матеріалу батьківських особин, забезпечуючи формування нащадків, що успадковують корисні ознаки від обох батьків. Бібліотека реалізує широкий спектр операторів кросинговеру, оптимізованих для роботи з різними типами змінних та придатних для різних класів оптимізаційних задач.

### Основні типи операторів кросинговеру

PaGMO2 підтримує чотири основні типи операторів кросинговеру, які реалізовані в класі SGA:

#### 1. Експоненціальний кросинговер (Exponential Crossover)

- **Принцип роботи**: починаючи з випадкової позиції, послідовно копіює гени від другого батька з ймовірністю `cr` до першого зупинення (коли випадкове число > `cr`)
- **Статистичні властивості**: очікувана кількість генів, що будуть обмінені, має геометричний розподіл:
  $$E[L] = \frac{1}{1-cr}$$
- **Походження**: адаптований з алгоритму диференціальної еволюції
- **Застосовність**: ефективний для задач з епістазисом (взаємозалежністю змінних, що знаходяться поруч)

```cpp
// Метод у класі sga, що виконує експоненціальний кросинговер
for (vector_double::size_type i = 0u; i < pop_size; ++i) {
    if (i % 2 == 0 && i + 1 < pop_size) {
        auto site = std::uniform_int_distribution<vector_double::size_type>(0, dim_c - 1)(m_e);
        auto count = 0u;

        // Починаємо експоненціальний кросинговер з вибраної позиції
        do {
            std::swap(X[i][site], X[i + 1][site]);
            site = (site + 1) % dim_c;
            count++;
        } while (std::uniform_real_distribution<>(0.0, 1.0)(m_e) < m_cr && count < dim_c);
    }
}
```

#### 2. Біноміальний кросинговер (Binomial Crossover)

- **Принцип роботи**: Для кожного гена з ймовірністю `cr` він береться від другого батька, інакше — від першого
- **Статистичні властивості**: кількість обмінюваних генів має біноміальний розподіл:
  $$L \sim B(n, cr)$$
  де $n$ — розмірність задачі
- **Особливості**: забезпечує більш рівномірний розподіл точок розриву порівняно з експоненціальним кросинговером
- **Застосовність**: універсальний оператор, ефективний для широкого спектру задач

```cpp
// Фрагмент коду біноміального кросинговеру
for (vector_double::size_type i = 0u; i < pop_size; i += 2) {
    if (i + 1 < pop_size) {
        for (vector_double::size_type j = 0u; j < dim_c; ++j) {
            if (std::uniform_real_distribution<>(0.0, 1.0)(m_e) < m_cr) {
                std::swap(X[i][j], X[i + 1][j]);
            }
        }
    }
}
```

#### 3. Одноточковий кросинговер (Single-Point Crossover)

- **Принцип роботи**: обирається випадкова точка перетину, до неї гени беруться від першого батька, після — від другого
- **Характеристики**: зберігає цілісні блоки генів, що може бути корисним при наявності зв'язаних ознак
- **Особливості**: найпростіший та історично перший оператор кросинговеру в генетичних алгоритмах
- **Застосовність**: підходить для задач, де блоки сусідніх генів мають семантичне значення

```cpp
// Фрагмент коду одноточкового кросинговеру
for (vector_double::size_type i = 0u; i < pop_size; i += 2) {
    if (i + 1 < pop_size) {
        // Випадкова точка перетину
        auto site = std::uniform_int_distribution<vector_double::size_type>(0, dim_c - 1)(m_e);
        for (vector_double::size_type j = site; j < dim_c; ++j) {
            std::swap(X[i][j], X[i + 1][j]);
        }
    }
}
```

#### 4. Імітаційний бінарний кросинговер (Simulated Binary Crossover, SBX)

- **Концепція**: спеціалізований оператор, що моделює ефект бінарного кросинговеру на дійсні змінні, зберігаючи властивості центрованості та дисперсії
- **Параметризація**: використовує параметр `eta_c` (індекс розподілу), що контролює схожість нащадків до батьків:
  - Низькі значення `eta_c` (~1) призводять до більшої різниці між нащадками та батьками
  - Високі значення `eta_c` (~100) призводять до нащадків, дуже схожих на батьків
- **Математична модель**: використовує спеціальну функцію розподілу для коефіцієнту розширення $\beta$:
  $$P(\beta) = \begin{cases}
    0.5(\eta_c+1)\beta^{\eta_c}, & \text{якщо } \beta \leq 1 \\
    0.5(\eta_c+1)\frac{1}{\beta^{\eta_c+2}}, & \text{інакше}
  \end{cases}$$
- **Походження**: розроблений Калянмоєм Дебом для збереження властивостей бінарного кросинговеру в неперервному просторі
- **Реалізація**: виділена у функцію `sbx_crossover()` в модулі `utils/genetic_operators`

```cpp
// Спрощена схема SBX кросинговеру (основні кроки з коду)
for (auto i = 0u; i < ncx; i++) {
    // Кросинговер відбувається з ймовірністю 0.5 для кожної змінної
    if (drng(random_engine) < 0.5 && std::abs(parent1[i] - parent2[i]) > 1e-14) {
        // Упорядкування значень
        double y1 = std::min(parent1[i], parent2[i]);
        double y2 = std::max(parent1[i], parent2[i]);
        double yl = lb[i];  // Нижня межа
        double yu = ub[i];  // Верхня межа

        // Обчислення коефіцієнтів бета та betaq
        double rand01 = drng(random_engine);
        double beta = 1. + (2. * (y1 - yl) / (y2 - y1));
        double betaq = sbx_betaq(beta, eta_c, rand01);

        // Обчислення нащадка 1
        double c1 = 0.5 * ((y1 + y2) - betaq * (y2 - y1));

        // Повторно для нащадка 2
        beta = 1. + (2. * (yu - y2) / (y2 - y1));
        betaq = sbx_betaq(beta, eta_c, rand01);
        double c2 = 0.5 * ((y1 + y2) + betaq * (y2 - y1));

        // Корекція меж
        c1 = std::clamp(c1, lb[i], ub[i]);
        c2 = std::clamp(c2, lb[i], ub[i]);

        // Призначення значень нащадкам
        child1[i] = (drng(random_engine) < 0.5) ? c1 : c2;
        child2[i] = (drng(random_engine) < 0.5) ? c2 : c1;
    }
}
```

### Особливості роботи з різними типами змінних

PaGMO2 адаптує оператори кросинговеру для роботи з різними типами змінних:

#### 1. Обробка неперервних змінних

- Для неперервних змінних застосовуються стандартні оператори кросинговеру (експоненціальний, біноміальний, одноточковий, SBX)
- Оператори враховують обмеження змінних, коригуючи значення нащадків до допустимих меж
- SBX спеціально розроблений для роботи з неперервними змінними та зберігає їх корисні статистичні властивості

#### 2. Обробка цілочисельних змінних

Для цілочисельних змінних PaGMO2 використовує спеціалізовані підходи:

- **Двоточковий кросинговер**: застосовується для цілочисельних частин хромосоми
- **Спеціальна обробка**: забезпечує, що змінні завжди набувають цілих значень
- **Позиціонування**: цілочисельні змінні повинні знаходитись в кінці вектора рішення

```cpp
// Двоточковий кросинговер для цілочисельних змінних
if (nix > 0u) {
    std::uniform_int_distribution<> ra_num(ncx, nx - 1u);
    site1 = ra_num(random_engine);
    site2 = ra_num(random_engine);
    if (site1 > site2) {
        std::swap(site1, site2);
    }
    // Обмін підрядками між батьками
    for (auto j = site1; j <= site2; ++j) {
        child1[j] = parent2[j];
        child2[j] = parent1[j];
    }
}
```

### Налаштовуваність та параметризація

Оператори кросинговеру в PaGMO2 надають значні можливості для налаштування:

#### 1. Основні параметри

- **Тип кросинговеру**: вибір між "exponential", "binomial", "single", "sbx"
- **Ймовірність кросинговеру (`cr`)**: значення в діапазоні [0,1], що визначає загальну вірогідність застосування кросинговеру
- **Індекс розподілу (`eta_c`)**: Для SBX, значення в діапазоні [1,100], контролює схожість нащадків до батьків

```cpp
// Налаштування SGA з різними параметрами кросинговеру
algorithm algo{sga(
    100,                // Кількість поколінь
    0.95,               // Ймовірність кросинговеру
    20.0,               // Індекс розподілу для SBX
    0.01,               // Ймовірність мутації
    1.0,                // Параметр мутації
    2,                  // Параметр селекції
    "sbx",              // Тип кросинговеру
    "polynomial",       // Тип мутації
    "tournament"        // Тип селекції
)};
```

#### 2. Особливі застосування

- **NSGA-II**: фіксовано використовує SBX кросинговер з налаштовуваним параметром `eta_c`
- **DE та його варіанти**: використовують власні механізми рекомбінації, подібні до кросинговеру

### Реалізація користувацьких операторів кросинговеру

Хоча PaGMO2 не має прямого інтерфейсу для впровадження нових операторів кросинговеру через композицію, користувач може:

1. **Створити власний алгоритм** з нестандартними операторами кросинговеру:

```cpp
struct custom_genetic_algorithm {
    population evolve(population pop) const {
        // ...
        // Власна імплементація кросинговеру
        for (auto i = 0u; i < pop_size; i += 2) {
            if (i + 1 < pop_size) {
                // Логіка користувацького кросинговеру
                custom_crossover(X[i], X[i+1], bounds, ...);
            }
        }
        // ...
        return pop;
    }

    // Допоміжна функція для користувацького кросинговеру
    void custom_crossover(vector_double &parent1, vector_double &parent2,
                         const std::pair<vector_double, vector_double> &bounds, ...) {
        // Імплементація власного оператора кросинговеру
    }

    // Інші необхідні методи...
};
```

2. **Адаптувати існуючий код** алгоритмів SGA або NSGA-II для власних потреб

Оператори кросинговеру в PaGMO2 забезпечують потужний механізм дослідження простору пошуку оптимізаційних задач. Комбінуючи різні типи кросинговеру з іншими генетичними операторами, користувачі можуть ефективно настроювати алгоритми для своїх конкретних задач.

## h. Оператори мутації, можливості їх налаштування

Оператори мутації є невід'ємною частиною генетичних алгоритмів в бібліотеці PaGMO2, що забезпечують локальне дослідження простору пошуку та підтримують генетичне різноманіття в популяції. PaGMO2 реалізує три основних типи мутації з різними характеристиками та параметрами налаштування, що адаптовані для різних типів змінних та класів задач.

### Основні типи операторів мутації

#### 1. Поліноміальна мутація (Polynomial Mutation)

Поліноміальна мутація є найбільш складним оператором мутації в PaGMO2, що забезпечує контрольоване збурення значень змінних:

- **Принцип роботи**: використовує поліноміальну формулу для генерації збурень з розподілом, що фаворизує малі зміни
- **Параметризація**: керується параметром `eta_m` (індекс розподілу), що контролює форму розподілу:
  - Низькі значення `eta_m` (~1) призводять до більших мутацій
  - Високі значення `eta_m` (~100) призводять до малих збурень, сконцентрованих біля початкового значення
- **Математична модель**: Для змінної $y$ з межами $[y_l, y_u]$ обчислюється:
  ```
  delta1 = (y - y_l) / (y_u - y_l)
  delta2 = (y_u - y) / (y_u - y_l)
  ```
  Потім, залежно від випадкового значення $r$:
  ```
  if r < 0.5:
      xy = 1 - delta1
      val = 2*r + (1-2*r)*(xy^(eta_m+1))
      deltaq = val^(1/(eta_m+1)) - 1
  else:
      xy = 1 - delta2
      val = 2*(1-r) + 2*(r-0.5)*(xy^(eta_m+1))
      deltaq = 1 - val^(1/(eta_m+1))
  ```
  Нове значення: `y = y + deltaq * (y_u - y_l)`

- **Використання в алгоритмах**: основний оператор мутації в NSGA-II та один з варіантів у SGA
- **Особливості для цілочисельних змінних**: використовує рівномірний розподіл для генерації цілих чисел у заданих межах

```cpp
// Фрагмент коду поліноміальної мутації для неперервної змінної
double delta1 = (y - yl) / (yu - yl);
double delta2 = (yu - y) / (yu - yl);
double rnd = drng(random_engine);
double mut_pow = 1. / (eta_m + 1.);

if (rnd < 0.5) {
    double xy = 1. - delta1;
    double val = 2. * rnd + (1. - 2. * rnd) * (std::pow(xy, (eta_m + 1.)));
    double deltaq = std::pow(val, mut_pow) - 1.;
    y = y + deltaq * (yu - yl);
} else {
    double xy = 1. - delta2;
    double val = 2. * (1. - rnd) + 2. * (rnd - 0.5) * (std::pow(xy, (eta_m + 1.)));
    double deltaq = 1. - (std::pow(val, mut_pow));
    y = y + deltaq * (yu - yl);
}

// Корекція меж
if (y < yl) y = yl;
if (y > yu) y = yu;
```

#### 2. Гаусівська мутація (Gaussian Mutation)

Гаусівська мутація додає випадкове збурення до змінної, використовуючи нормальний розподіл:

- **Принцип роботи**: Додає до значення змінної випадкове число, згенероване з нормального розподілу
- **Параметризація**: використовує параметр `param_m`, що контролює стандартне відхилення відносно ширини діапазону змінної
- **Математична модель**: Для змінної $x$ з межами $[l, u]$ нове значення обчислюється як:
  $$x' = x + \mathcal{N}(0, (u-l) \cdot \text{param\_m})$$
- **Особливості для цілочисельних змінних**: округляє результат до найближчого цілого числа

```cpp
// Гаусівська мутація в SGA
auto std = (ub[gene_idx] - lb[gene_idx]) * m_param_m;
if (gene_idx < dimc) {
    // Для неперервних змінних
    X[i][gene_idx] += normal(m_e) * std;
} else {
    // Для цілочисельних змінних - з округленням
    X[i][gene_idx] += std::round(normal(m_e) * std);
}
```

#### 3. Рівномірна мутація (Uniform Mutation)

Рівномірна мутація повністю замінює значення змінної новим випадковим значенням з її допустимого діапазону:

- **Принцип роботи**: генерує нове значення рівномірно з допустимого діапазону змінної, незалежно від поточного значення
- **Характеристики**: забезпечує найсильніший рівень дослідження, але втрачає всю інформацію про поточне значення змінної
- **Математична модель**: Для змінної $x$ з межами $[l, u]$ нове значення обчислюється як:
  $$x' \sim \mathcal{U}(l, u)$$
- **Особливості для цілочисельних змінних**: використовує рівномірний цілочисельний розподіл

```cpp
// Рівномірна мутація в SGA
if (gene_idx < dimc) {
    // Для неперервних змінних
    X[i][gene_idx] = uniform_real_from_range(lb[gene_idx], ub[gene_idx], m_e);
} else {
    // Для цілочисельних змінних
    rnd_lb_ub.param(std::uniform_int_distribution<int>::param_type(
        static_cast<int>(lb[gene_idx]), static_cast<int>(ub[gene_idx])));
    X[i][gene_idx] = static_cast<double>(rnd_lb_ub(m_e));
}
```

### Контроль інтенсивності мутації

PaGMO2 надає кілька механізмів для контролю інтенсивності мутації:

#### 1. Ймовірність мутації

- **Параметр**: `m` — ймовірність мутації кожного гена (зазвичай в діапазоні [0, 0.1])
- **Вплив**: визначає, яка частина генів хромосоми буде мутувати
- **Рекомендації**:
  - Для невеликих розмірностей задачі: ~0.01-0.1
  - Для великих розмірностей: ~1/n, де n — кількість змінних

```cpp
// Приклад застосування ймовірності мутації
std::vector<vector_double::size_type> to_be_mutated;
for (decltype(dim) j = 0u; j < dim; ++j) {
    if (drng(m_e) < m_m) {
        to_be_mutated.push_back(j);
    }
}
```

#### 2. Параметри розподілу мутації

- **Поліноміальна мутація**: `eta_m` — індекс розподілу (зазвичай 20-100)
- **Гаусівська мутація**: `param_m` — коефіцієнт масштабування стандартного відхилення (зазвичай 0.1-1.0)

#### 3. Адаптивна мутація

PaGMO2 не містить стандартних механізмів адаптивної мутації, але деякі алгоритми (як SADE) реалізують автоадаптацію параметрів мутації під час виконання.

### Обробка різних типів змінних

PaGMO2 забезпечує диференційований підхід до мутації різних типів змінних:

#### 1. Неперервні змінні

- Оператори мутації застосовуються безпосередньо до значень змінних
- Корекція меж гарантує, що мутовані значення залишаються в допустимому діапазоні

#### 2. Цілочисельні змінні

- **Поліноміальна мутація**: замінює на нове випадкове ціле число з допустимого діапазону
- **Гаусівська мутація**: Додає нормально розподілене збурення з подальшим округленням
- **Рівномірна мутація**: генерує нове ціле число рівномірно з діапазону

```cpp
// Поліноміальна мутація для цілочисельних змінних
for (decltype(nx) j = ncx; j < nx; ++j) {
    if (drng(random_engine) < p_m) {
        // Генерація випадкового цілого в [lb, ub]
        auto mutated = uniform_integral_from_range(lb[j], ub[j], random_engine);
        child[j] = mutated;
    }
}
```

### Реалізація та налаштування операторів мутації

#### 1. Конфігурація в SGA

```cpp
// Конструктор SGA з параметрами мутації
sga(unsigned gen = 1u,               // Кількість поколінь
    double cr = .90,                 // Ймовірність кросинговеру
    double eta_c = 1.,               // Параметр SBX кросинговеру
    double m = 0.02,                 // Ймовірність мутації
    double param_m = 1.,             // Параметр мутації (етa_m або ширина Гаусса)
    unsigned param_s = 2u,           // Параметр селекції
    std::string crossover = "exponential",
    std::string mutation = "polynomial", // Тип мутації: "polynomial", "gaussian", "uniform"
    std::string selection = "tournament",
    unsigned seed = pagmo::random_device::next());
```

#### 2. Конфігурація в NSGA-II

```cpp
// Конструктор NSGA-II з параметрами мутації
nsga2(unsigned gen = 1u,             // Кількість поколінь
      double cr = 0.95,              // Ймовірність кросинговеру
      double eta_c = 10.,            // Параметр SBX кросинговеру
      double m = 0.01,               // Ймовірність мутації
      double eta_m = 50.,            // Параметр поліноміальної мутації
      unsigned seed = pagmo::random_device::next());
```

### Створення користувацьких операторів мутації

PaGMO2 не надає прямого інтерфейсу для впровадження нових операторів мутації шляхом композиції, але користувач може:

1. **Обрати та налаштувати один з трьох стандартних операторів** при використанні SGA

2. **Створити власний алгоритм з користувацьким оператором мутації**:

```cpp
struct custom_evolutionary_algorithm {
    population evolve(population pop) const {
        // ...

        // Власна імплементація мутації
        for (decltype(pop.size()) i = 0u; i < pop.size(); ++i) {
            vector_double x = pop.get_x()[i];

            // Логіка користувацької мутації
            custom_mutation(x, prob.get_bounds(), p_m, ...);

            // Оцінка фітнесу та оновлення популяції
            if (prob.fitness(x) < pop.get_f()[i]) {
                pop.set_xf(i, x, prob.fitness(x));
            }
        }

        // ...
        return pop;
    }

    // Допоміжна функція для користувацької мутації
    void custom_mutation(vector_double &x,
                        const std::pair<vector_double, vector_double> &bounds,
                        double p_m, ...) {
        // Імплементація власного оператора мутації
    }

    // Інші необхідні методи...
};
```

3. **Адаптувати існуючий код** алгоритмів SGA або NSGA-II для впровадження нових операторів мутації

Оператори мутації в PaGMO2 надають гнучкий інструментарій для балансування між локальним пошуком (експлуатацією) та глобальним дослідженням простору рішень. Вибір та налаштування параметрів мутації є критичним для ефективного пошуку оптимального рішення в різних класах оптимізаційних задач.

## i. Оператори інверсії, можливості їх налаштування

### Стан реалізації операторів інверсії в PaGMO2

На відміну від операторів кросинговеру та мутації, PaGMO2 не містить вбудованих операторів інверсії для генетичних алгоритмів. Інверсія, як генетичний оператор, що змінює порядок генів у хромосомі шляхом реверсування послідовності генів на деякому відрізку, не представлена в стандартній бібліотеці. Аналіз кодової бази PaGMO2 показав відсутність прямих імплементацій цього оператора в наступних ключових компонентах:

1. **Модуль генетичних операторів**: основні генетичні оператори зосереджені в файлах `include/pagmo/utils/genetic_operators.hpp` та `src/utils/genetic_operators.cpp`, які містять реалізації кросинговеру та мутації, але не містять реалізацій інверсії.

2. **Реалізації генетичних алгоритмів**: класи `sga`, `nsga2` та інші не використовують оператори інверсії в процесі еволюції популяції.

### Потенційні шляхи впровадження операторів інверсії

Хоча PaGMO2 не надає готових операторів інверсії, архітектура бібліотеки дозволяє розширювати її функціональність через створення власних алгоритмів. Нижче описано можливі підходи до впровадження операторів інверсії:

#### 1. Розширення модуля генетичних операторів

```cpp
// Приклад можливої імплементації оператора інверсії
void inversion(vector_double &chromosome,
               double inversion_rate,
               detail::random_engine_type &random_engine)
{
    // Розмірність хромосоми
    auto n = chromosome.size();

    // Інверсія застосовується з імовірністю inversion_rate
    std::uniform_real_distribution<> drng(0., 1.);
    if (drng(random_engine) < inversion_rate) {
        // Вибір двох випадкових точок на хромосомі
        std::uniform_int_distribution<vector_double::size_type>
            irng(0, n - 1);
        auto start = irng(random_engine);
        auto end = irng(random_engine);

        // Забезпечення, що start < end
        if (start > end) {
            std::swap(start, end);
        }

        // Реверсування порядку генів у вибраному сегменті
        std::reverse(chromosome.begin() + start, chromosome.begin() + end + 1);
    }
}
```

#### 2. Інтеграція інверсії в користувацький генетичний алгоритм

```cpp
struct custom_ga_with_inversion {
    population evolve(population pop) const {
        // ...

        // Застосування інверсії після інших генетичних операторів
        for (decltype(pop.size()) i = 0u; i < pop.size(); ++i) {
            vector_double x = pop.get_x()[i];

            // Застосування інверсії
            inversion(x, m_inversion_rate, m_e);

            // Оцінка фітнесу та оновлення популяції, якщо потрібно
            auto f = prob.fitness(x);
            if (compare_fitness(f, pop.get_f()[i], prob)) {
                pop.set_xf(i, x, f);
            }
        }

        // ...
        return pop;
    }

    // Інші необхідні методи та параметри
    double m_inversion_rate;
    mutable detail::random_engine_type m_e;
};
```

### Параметризація оператора інверсії

У разі впровадження оператора інверсії, його можна параметризувати наступним чином:

- **Імовірність інверсії (`inversion_rate`)**: визначає шанс застосування інверсії до хромосоми (зазвичай невелике значення, 0.01-0.05)
- **Метод вибору сегмента**: визначає, як вибирати сегмент для інверсії (рівномірний вибір, функціонально-орієнтований, тощо)
- **Момент застосування**: До, після, чи незалежно від інших генетичних операторів

### Специфіка для різних типів змінних

При впровадженні операторів інверсії слід враховувати специфіку різних типів змінних:

#### 1. Неперервні змінні

Пряме застосування інверсії для неперервних змінних може бути неефективним через руйнування структури рішення. Для неперервних змінних більш доцільно:
- Використовувати інверсію на специфічних сегментах, де змінні мають семантичний зв'язок
- Застосовувати інверсію з дуже низькою ймовірністю

#### 2. Цілочисельні та дискретні змінні

Інверсія потенційно більш корисна для задач з цілочисельними чи дискретними змінними, особливо якщо ці змінні представляють перестановки або послідовності.

### Висновки щодо операторів інверсії

Відсутність вбудованих операторів інверсії в PaGMO2 може бути обґрунтована декількома факторами:

1. **Обмежена ефективність**: Дослідження показують, що інверсія часто має обмежений вплив на ефективність генетичних алгоритмів для більшості класів оптимізаційних задач

2. **Специфічність застосування**: інверсія найкорисніша для специфічних класів задач (наприклад, перестановочних задач як задача комівояжера), які не є основним фокусом PaGMO2

3. **Модульна архітектура**: архітектура PaGMO2 дозволяє користувачам впроваджувати власні алгоритми з необхідними операторами, коли це потрібно

Хоча PaGMO2 не надає вбудованої підтримки операторів інверсії, гнучка архітектура бібліотеки дозволяє користувачам розширювати її функціональність та впроваджувати власні оператори для специфічних задач.

## j. Інші вбудовані можливості

PaGMO2 представляє широкий набір додаткових можливостей для розв'язання різноманітних оптимізаційних задач, що виходять за рамки базових генетичних алгоритмів. Розглянемо ключові розширені можливості, що дозволяють ефективно застосовувати бібліотеку до складних практичних задач.

### Багатокритеріальна оптимізація (Multi-objective optimization)

PaGMO2 надає потужну підтримку для багатокритеріальної оптимізації через набір алгоритмів та утиліт:

#### 1. Спеціалізовані алгоритми

- **NSGA-II** (Non-dominated Sorting Genetic Algorithm II):
  ```cpp
  // Створення та використання NSGA-II
  problem prob{zdt{1u}};  // ZDT1 - стандартна тестова багатокритеріальна задача
  algorithm algo{nsga2(100, 0.95, 10., 0.01, 50.)}; // 100 поколінь
  population pop{prob, 100};  // популяція розміром 100
  pop = algo.evolve(pop);     // еволюція популяції
  ```

- **MOEA/D** (Multi-objective Evolutionary Algorithm Based on Decomposition):
  ```cpp
  // Декомпозиція багатокритеріальної задачі на скалярні підзадачі
  algorithm algo{moead()};
  ```

- **NSPSO** (Non-dominated Sorting Particle Swarm Optimization)

#### 2. Утиліти для багатокритеріальної оптимізації

- **Парето-домінування**:
  ```cpp
  // Перевірка, чи домінує f1 над f2
  bool is_dominating = pareto_dominance(f1, f2);
  ```

- **Недоміноване сортування**:
  ```cpp
  // Сортування популяції за фронтами Парето
  auto fronts = fast_non_dominated_sorting(fitnesses);
  ```

- **Гіперобʼєм** - метрика для оцінки якості багатокритеріальних наближень:
  ```cpp
  // Обчислення гіперобʼєму Парето-фронту
  hypervolume hv(population_points);
  double volume = hv.compute(reference_point);
  ```

- **Пошук референсних точок**:
  ```cpp
  // Знаходження ідеальної та надир-точок
  auto ideal_pt = ideal(points);
  auto nadir_pt = nadir(points);
  ```

- **Декомпозиція багатокритеріальних задач**:
  ```cpp
  // Генерація вагових векторів для декомпозиції
  auto weights = decomposition_weights(3u, 100u, "low discrepancy", r_engine);

  // Декомпозиція цільових функцій
  auto scalar_f = decompose_objectives(f, weight, ref_point, "tchebycheff");
  ```

### Мультимодальна оптимізація (Multi-modal optimization)

PaGMO2 підтримує пошук множинних оптимумів через алгоритми, що зберігають різноманіття:

#### 1. Алгоритми глобальної оптимізації

- **Monotonic Basin Hopping (MBH)**: ефективний алгоритм для мультимодальних ландшафтів
  ```cpp
  algorithm algo{mbh(local_optimizer, stop_range, perturb_range)};
  ```

- **Simulated Annealing**: метод імітації відпалу з можливістю перезапуску
  ```cpp
  algorithm algo{simulated_annealing(Ts, Tf, n_T_adj, n_range_adj, bin_size, start_range)};
  ```

#### 2. Підходи для збереження різноманіття

- **Островна модель**: природний спосіб підтримки різноманіття через паралельну еволюцію підпопуляцій
- **Політики селекції/заміни**: можливість налаштовувати правила відбору та заміни особин для збереження різноманіття

### Підтримка динамічної оптимізації (Dynamic optimization)

PaGMO2 містить механізми для задач з динамічними характеристиками:

- **Адаптивні алгоритми**: наприклад, SADE - Self-Adaptive Differential Evolution
  ```cpp
  algorithm algo{sade()};  // Самоадаптивна диференціальна еволюція
  ```

- **Адаптивна обробка обмежень**: алгоритм `cstrs_self_adaptive` для динамічної адаптації до обмежень
  ```cpp
  algorithm algo{cstrs_self_adaptive(iters_without_imp)};
  ```

### Островні моделі та паралелізація (Island models and parallelization)

Одна з найсильніших сторін PaGMO2 - підтримка масштабованої паралелізації:

#### 1. Архіпелаг

Архіпелаг є високорівневою абстракцією для управління набором островів:

```cpp
// Створення архіпелагу з 16 островів
archipelago archi{16u, algo, prob, 20u};

// Еволюція архіпелагу
archi.evolve(10);  // 10 поколінь еволюції
archi.wait_check();  // Очікування завершення
```

#### 2. Топології міграції

PaGMO2 підтримує різні топології для міграції особин між островами:

- **Повнозв'язна (Fully Connected)**: кожен острів зв'язаний з усіма іншими
  ```cpp
  topology topo{fully_connected()};
  ```

- **Кільцева (Ring)**: острови з'єднані в одному напрямку
  ```cpp
  topology topo{ring()};
  ```

- **Вільна форма (Free Form)**: користувацька топологія з явно заданими зв'язками
  ```cpp
  topology topo{free_form()};
  topo.push_back();
  topo.add_edge(0, 1);
  ```

#### 3. Політики міграції

PaGMO2 дозволяє налаштовувати політики міграції:

- **Тип міграції**: `migration_type::p2p` (точка до точки) чи `migration_type::broadcast` (широкомовна)
- **Обробка мігрантів**: `migrant_handling::preserve` (зберігати) чи `migrant_handling::evict` (видаляти) мігрантів після міграції

#### 4. Паралельні обчислення

PaGMO2 підтримує паралельне виконання через:

- **Thread Island**: острів, що використовує потоки C++ для паралельної еволюції
  ```cpp
  island isl{thread_island(), algo, prob, 20u};
  ```

- **Fork Island**: острів, що використовує процеси ОС для паралельної еволюції
  ```cpp
  island isl{fork_island(), algo, prob, 20u};
  ```

- **Пакетні обчислювачі фітнесу (BFE)**: ефективна паралельна обробка обчислень функцій пристосованості
  ```cpp
  bfe parallel_evaluator{thread_bfe{}};
  prob.batch_fitness(xs, parallel_evaluator);
  ```

### Інші спеціалізовані можливості

#### 1. Утиліти для роботи з обмеженнями

- **Перетворення обмежених задач в необмежені**:
  ```cpp
  problem unconstrained_prob{unconstrain{constrained_prob, "weighted"}};
  ```

- **Утиліти для перевірки обмежень**: `test_eq_constraints()`, `test_ineq_constraints()`

#### 2. Обробка градієнтів та гессіанів

PaGMO2 підтримує роботу з диференційованими функціями:

- **Градієнти**: Для задач, що надають аналітичні градієнти
- **Гессіани**: Для задач з доступними матрицями других похідних

#### 3. Послідовності з низькою розбіжністю (Low Discrepancy Sequences)

Для рівномірного покриття простору пошуку:

```cpp
// Генерація послідовності Холтона
halton seq{10, 0};
auto sample = seq();
```

### Порівняння можливостей для різних типів оптимізаційних задач

| Тип задачі | Підтримка PaGMO2 | Доступні алгоритми |
|------------|------------------|-------------------|
| Однокритеріальна | Відмінна | Всі (>20 алгоритмів) |
| Багатокритеріальна | Відмінна | NSGA-II, MOEAD, NSPSO |
| Мультимодальна | Хороша | MBH, Simulated Annealing, островні моделі |
| Динамічна | Обмежена | SADE, cstrs_self_adaptive |
| З обмеженнями | Відмінна | Більшість алгоритмів, unconstrain, спеціалізовані утиліти |
| Змішаної цілочисельності | Хороша | Адаптовані генетичні оператори |
| Паралельна | Відмінна | Архіпелаг, Thread/Fork Islands, BFE |

PaGMO2 пропонує потужний та гнучкий інструментарій для роботи з широким спектром оптимізаційних задач, виходячи за рамки стандартних генетичних алгоритмів та забезпечуючи функціональність для ефективної роботи зі складними реальними проблемами оптимізації.

## k. Пропоновані методи налаштування параметрів та способи їх використання

Ефективність роботи генетичних алгоритмів та інших методів оптимізації істотно залежить від коректного вибору їх параметрів. PaGMO2 не містить вбудованих спеціалізованих фреймворків для автоматичного налаштування параметрів, таких як SPO (Sequential Parameter Optimization), SMBO (Sequential Model-Based Optimization) чи інших, але пропонує ряд механізмів для контролю та самоадаптації параметрів у процесі оптимізації.

### Інтеграція з методами автоматичного налаштування параметрів

Хоча PaGMO2 не має прямої реалізації SPO та SMBO, архітектура бібліотеки дозволяє легко інтегрувати ці методи:

#### 1. Послідовна оптимізація параметрів (SPO)

SPO - це метод, що послідовно покращує налаштування параметрів, використовуючи сурогатні моделі (зазвичай гаусівські процеси) для прогнозування продуктивності алгоритму з новими параметрами:

```python
# Приклад реалізації SPO з використанням PyGMO та scikit-learn
import pygmo as pg
from sklearn.gaussian_process import GaussianProcessRegressor
import numpy as np

# Функція оцінки якості конфігурації параметрів
def evaluate_configuration(config, problem, n_runs=5):
    cr, m, tournament_size = config
    results = []

    for seed in range(n_runs):
        # Створення алгоритму з конфігурацією
        algo = pg.algorithm(pg.sga(100, cr, 1.0, m, 1.0, tournament_size, seed=seed))
        pop = pg.population(problem, 20)
        pop = algo.evolve(pop)
        results.append(pop.champion_f()[0])

    return np.mean(results)  # Середнє значення фітнеса

# Основний цикл SPO
def spo_tuning(problem, n_iterations=10, n_initial=5):
    # Початкова вибірка конфігурацій
    configs = np.random.rand(n_initial, 3)  # [cr, m, tournament_size]
    configs[:, 2] = np.random.randint(2, 8, size=n_initial)  # tournament_size в діапазоні [2,7]

    # Оцінка початкових конфігурацій
    performances = [evaluate_configuration(config, problem) for config in configs]

    # Створення та навчання сурогатної моделі
    model = GaussianProcessRegressor()

    for i in range(n_iterations):
        # Навчання моделі на поточних даних
        model.fit(configs, performances)

        # Генерація та оцінка нових кандидатів
        candidates = np.random.rand(100, 3)
        candidates[:, 2] = np.random.randint(2, 8, size=100)

        # Прогнозування та вибір найкращого кандидата
        predictions, stds = model.predict(candidates, return_std=True)
        acquisition = predictions - 0.5 * stds  # Acquisition function (EI simplified)
        best_idx = np.argmin(acquisition)

        # Оцінка обраного кандидата
        new_config = candidates[best_idx]
        new_performance = evaluate_configuration(new_config, problem)

        # Оновлення даних
        configs = np.vstack([configs, [new_config]])
        performances.append(new_performance)

    # Повернення найкращої конфігурації
    best_idx = np.argmin(performances)
    return configs[best_idx]
```

#### 2. Послідовна оптимізація на основі моделей (SMBO)

SMBO - це узагальнення SPO, що включає різні техніки та алгоритми для побудови й використання сурогатних моделей. Інтеграція SMBO з PaGMO2 можлива через спеціалізовані бібліотеки:

```python
# Приклад використання SMBO через бібліотеку Optuna
import optuna
import pygmo as pg

def objective(trial):
    # Параметризація SGA через Optuna
    cr = trial.suggest_float('crossover_rate', 0.5, 1.0)
    m = trial.suggest_float('mutation_rate', 0.001, 0.1)
    eta_c = trial.suggest_float('eta_c', 1.0, 30.0)
    eta_m = trial.suggest_float('eta_m', 1.0, 100.0)
    tournament_size = trial.suggest_int('tournament_size', 2, 7)

    # Вибір типу кросинговеру
    crossover_type = trial.suggest_categorical('crossover', ['exponential', 'binomial', 'sbx'])

    # Вибір типу мутації
    mutation_type = trial.suggest_categorical('mutation', ['polynomial', 'gaussian', 'uniform'])

    # Обчислення середньої продуктивності для зменшення шуму
    fitness_values = []
    for seed in range(5):
        algo = pg.algorithm(pg.sga(
            100, cr, eta_c, m, eta_m, tournament_size,
            crossover_type, mutation_type, "tournament", seed
        ))
        prob = pg.problem(pg.schwefel(30))
        pop = pg.population(prob, 50)
        pop = algo.evolve(pop)
        fitness_values.append(pop.champion_f()[0])

    return sum(fitness_values) / len(fitness_values)

# Створення дослідження та запуск оптимізації
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100)

# Аналіз результатів та візуалізація
print("Best parameters:", study.best_params)
optuna.visualization.plot_param_importances(study)
optuna.visualization.plot_slice(study)
```

#### 3. Варіанти впровадження інших підходів

Окрім SPO та SMBO, з PaGMO2 можуть бути інтегровані інші підходи:

- **Решітчастий пошук (Grid Search)**: повний перебір комбінацій параметрів
- **Випадковий пошук (Random Search)**: ефективна альтернатива перебору для просторів великої розмірності
- **Байєсівська оптимізація**: імплементація через бібліотеки scikit-optimize або GPyOpt
- **Генетичні алгоритми для налаштування параметрів**: мета-рівень оптимізації, де генетичний алгоритм PaGMO2 налаштовує параметри іншого алгоритму

Приклад реалізації метагенетичного алгоритму:

```cpp
// Проблема оптимізації параметрів SGA
struct sga_tuning_problem {
    vector_double fitness(const vector_double &x) const {
        // Параметри SGA для налаштування
        double cr = x[0];            // Ймовірність кросинговеру [0.5, 1.0]
        double m = x[1];             // Ймовірність мутації [0.001, 0.1]
        double eta_c = x[2];         // Індекс розподілу SBX [1.0, 30.0]
        double tournament_size = x[3]; // Розмір турніру [2, 7]

        // Конфігурація алгоритму SGA з параметрами
        algorithm algo{sga(
            100, cr, eta_c, m, 1.0,
            static_cast<unsigned>(std::round(tournament_size)),
            "sbx", "polynomial", "tournament"
        )};

        // Тестова задача
        problem prob{schwefel(30)};

        // Усереднення результатів з різними seed
        double avg_fitness = 0.0;
        const unsigned n_runs = 5;

        for (unsigned seed = 1; seed <= n_runs; ++seed) {
            // Ініціалізація популяції з фіксованим seed
            population pop{prob, 50, seed};
            // Еволюція
            pop = algo.evolve(pop);
            // Накопичення результатів
            avg_fitness += pop.champion_f()[0];
        }

        return {avg_fitness / n_runs};
    }

    std::pair<vector_double, vector_double> get_bounds() const {
        return {{0.5, 0.001, 1.0, 2.0}, {1.0, 0.1, 30.0, 7.0}};
    }
};

// Використання метагенетичного алгоритму
problem meta_prob{sga_tuning_problem{}};
algorithm meta_algo{de(50, 0.8, 0.9, 2)};  // DE для оптимізації параметрів
population meta_pop{meta_prob, 20};
meta_pop = meta_algo.evolve(meta_pop);

// Отримання оптимальних параметрів
vector_double best_params = meta_pop.champion_x();
std::cout << "Optimal parameters: cr=" << best_params[0]
          << ", m=" << best_params[1]
          << ", eta_c=" << best_params[2]
          << ", tournament_size=" << std::round(best_params[3]) << std::endl;
```

### Самоадаптивні алгоритми

#### 1. Самоадаптивна диференціальна еволюція (SADE)

PaGMO2 реалізує алгоритм SADE, що забезпечує автоматичну адаптацію ключових параметрів диференціальної еволюції (CR та F):

```cpp
algorithm algo{sade(
    variant,        // Варіант самоадаптації: 1 - jDE (Brest), 2 - iDE (Elsayed)
    gen,            // Кількість поколінь
    variant_adptv,  // Варіант диференціальної еволюції: 1 - rand/1/bin, 18 - варіантів
    ftol,           // Толерантність за значенням фітнеса
    xtol,           // Толерантність за значенням вектора рішення
    memory          // Використання пам'яті
)};
```

Алгоритм SADE підтримує два основних механізми самоадаптації:

1. **jDE (Brest et al.)**: механізм контролю параметрів, де нові значення CR та F не використовують оператори DE
   ```cpp
   // Основний принцип оновлення параметрів у jDE
   if (drng(m_e) < m_jde_tau_f) {
       // Нове значення F для поточної особини
       Fi = drng(m_e) * 0.9 + 0.1;  // F у [0.1, 1.0]
   }

   if (drng(m_e) < m_jde_tau_cr) {
       // Нове значення CR для поточної особини
       CRi = drng(m_e);  // CR у [0, 1]
   }
   ```

2. **iDE (Elsayed et al.)**: справжня самоадаптація, де оператори DE використовуються для генерації нових значень CR та F
   ```cpp
   // Використання варіації DE оператора для створення нових CR та F
   // Нові F_i та CR_i генеруються з використанням мутації та кросинговеру
   ```

#### 2. Самоадаптивна обробка обмежень (cstrs_self_adaptive)

PaGMO2 надає мета-алгоритм для адаптивної обробки обмежень, що автоматично налаштовує параметри штрафів:

```cpp
algorithm algo{cstrs_self_adaptive(
    iters_without_imp  // Кількість ітерацій без покращення
)};
```

Цей алгоритм:
- Обгортає будь-який інший алгоритм оптимізації
- Динамічно адаптує штрафні коефіцієнти для обмежень
- Дозволяє базовому алгоритму "бачити" обмежену задачу як необмежену

### Мета-алгоритми для пошуку оптимальних налаштувань

#### 1. Monotonic Basin Hopping (MBH)

MBH - це мета-алгоритм, що може використовуватись для уникнення локальних оптимумів та, неявно, для пошуку кращих налаштувань:

```cpp
algorithm algo{mbh(
    inner_algo,      // Внутрішній алгоритм оптимізації
    stop_range,      // Критерій зупинки
    perturb_range,   // Діапазон збурень
    n_perturb,       // Кількість збурень
    seed             // Початкове значення генератора випадкових чисел
)};
```

MBH може використовуватись як базис для реалізації методів налаштування параметрів:
- Збурення можуть застосовуватись до параметрів алгоритму
- Процес оптимізації може оцінювати якість різних налаштувань

### Підхід з використанням острівної моделі

Хоча PaGMO2 не має стандартного методу для оцінки різних конфігурацій параметрів, острівна модель архіпелагу може ефективно використовуватись для паралельного дослідження простору параметрів:

```cpp
// Створення кількох алгоритмів з різними параметрами
algorithm algo1{sga(100, 0.8, 1.0, 0.02, 1.0, 2, "exponential", "polynomial", "tournament")};
algorithm algo2{sga(100, 0.9, 1.0, 0.05, 1.0, 2, "exponential", "polynomial", "tournament")};
algorithm algo3{sga(100, 0.7, 1.0, 0.01, 1.0, 2, "exponential", "polynomial", "tournament")};

// Створення островів з різними алгоритмами
island isl1{algo1, prob, 20};
island isl2{algo2, prob, 20};
island isl3{algo3, prob, 20};

// Об'єднання в архіпелаг
archipelago archi{isl1, isl2, isl3};
archi.evolve();
archi.wait_check();

// Порівняння результатів
auto best_algo = std::min_element(archi.begin(), archi.end(),
    [](const auto &isl1, const auto &isl2) {
        return isl1.get_population().champion_f()[0] < isl2.get_population().champion_f()[0];
    });
```

### Реалізація власних стратегій налаштування параметрів

Хоча PaGMO2 не надає готових реалізацій SPO чи SMBO, його гнучка архітектура дозволяє впроваджувати власні стратегії налаштування:

#### 1. Вкладені мета-алгоритми

```cpp
struct param_tuner {
    population evolve(population pop) const {
        // Створення варіантів внутрішнього алгоритму з різними параметрами
        algorithm algo1{sga(100, 0.8, 1.0, 0.02, 1.0)};
        algorithm algo2{sga(100, 0.9, 1.0, 0.05, 1.0)};

        // Оцінка кожного варіанта
        population pop1 = pop;
        population pop2 = pop;

        pop1 = algo1.evolve(pop1);
        pop2 = algo2.evolve(pop2);

        // Вибір кращого варіанта
        if (pop1.champion_f()[0] < pop2.champion_f()[0]) {
            return pop1;
        } else {
            return pop2;
        }
    }
};

algorithm meta_algo{param_tuner{}};
```

#### 2. Інтеграція з зовнішніми системами налаштування

PaGMO2 може бути інтегрований із зовнішніми системами налаштування параметрів:

```python
# Приклад інтеграції з бібліотекою Optuna для байєсівської оптимізації (Python код)
import optuna
import pygmo as pg

def objective(trial):
    # Параметризація SGA через Optuna
    cr = trial.suggest_float('cr', 0.5, 1.0)
    m = trial.suggest_float('m', 0.001, 0.1)

    # Створення та запуск алгоритму з цими параметрами
    algo = pg.algorithm(pg.sga(100, cr, 1.0, m, 1.0))
    prob = pg.problem(pg.schwefel(30))
    pop = pg.population(prob, 20)
    pop = algo.evolve(pop)

    # Повернення цільової метрики для оптимізації
    return pop.champion_f()[0]

# Запуск Optuna для пошуку оптимальних параметрів
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100)

# Отримання найкращих параметрів
best_params = study.best_params
```

### Рекомендовані практики налаштування параметрів для PaGMO2

#### 1. Базові рекомендовані налаштування для генетичних алгоритмів:

| Параметр | Типовий діапазон | Рекомендація | Примітки |
|----------|------------------|--------------|----------|
| Розмір популяції | 20-200 | 10*n - 100*n | n - розмірність задачі |
| Імовірність кросинговеру | 0.7-1.0 | 0.9 | Вища для SGA, нижча для NSGA-II |
| Імовірність мутації | 0.001-0.1 | 1/n | n - розмірність задачі |
| Розмір турніру | 2-7 | 2-3 | Вищі значення посилюють селективний тиск |
| Індекс SBX (eta_c) | 1-100 | 10-30 | Вищі значення - ближчі до батьків нащадки |
| Індекс мутації (eta_m) | 1-100 | 20-50 | Вищі значення - менша шкала мутацій |

#### 2. Покрокова стратегія налаштування:

1. **Починайте з типових налаштувань** для відповідного класу задач
2. **Використовуйте острівну модель** для паралельного тестування різних конфігурацій
3. **Для задач з шумом або складною структурою** використовуйте самоадаптивні алгоритми
4. **Для критичних задач** реалізуйте мета-оптимізацію параметрів через зовнішні інструменти

Хоча PaGMO2 не містить вбудованих спеціалізованих фреймворків для автоматичного налаштування параметрів, його гнучка архітектура та наявність самоадаптивних алгоритмів надають достатню основу для ефективної оптимізації параметрів через ручне налаштування, острівний підхід або інтеграцію з зовнішніми системами налаштування.

## l. Пропоновані підходи до експериментального аналізу

PaGMO2 орієнтований насамперед на імплементацію алгоритмів оптимізації, а не на комплексний аналіз результатів. Тим не менш, бібліотека надає ряд інструментів та підходів для оцінки якості отриманих рішень, збору даних про процес оптимізації та аналізу результатів. Розглянемо наявні можливості для експериментального аналізу та розширені підходи до оцінки ефективності генетичних алгоритмів.

### Метрики якості оптимізації

#### 1. Метрики для однокритеріальної оптимізації

- **Значення фітнес-функції**: основна метрика для оцінки якості рішення
  ```cpp
  // Отримання значення фітнес-функції для найкращого рішення
  double best_fitness = pop.champion_f()[0];
  ```

- **Відстеження прогресу**: Дані про покращення рішень у процесі оптимізації
  ```cpp
  // Отримання логу алгоритму
  const auto &log = algo.get_log();
  // log містить дані про значення функції на кожній ітерації
  ```

#### 2. Метрики для багатокритеріальної оптимізації

- **Гіперобʼєм (Hypervolume)**: ключова метрика для оцінки якості Парето-фронту
  ```cpp
  // Обчислення гіперобʼєму
  hypervolume hv(pop_points);
  double vol = hv.compute(reference_point);

  // Індивідуальні внески точок
  auto least_contributor_idx = hv.least_contributor(reference_point);
  auto contributions = hv.contributions(reference_point);
  ```

- **Метрики домінування (Dominance metrics)**:
  ```cpp
  // Визначення недомінованих фронтів
  auto fronts_data = fast_non_dominated_sorting(fitnesses);
  auto fronts = std::get<0>(fronts_data);  // Парето-фронти
  ```

- **Метрика скупченості (Crowding distance)**:
  ```cpp
  // Обчислення метрики скупченості для точок Парето-фронту
  auto crowd_dist = crowding_distance(front_points);
  ```

- **Референсні точки**:
  ```cpp
  // Обчислення ідеальної та надир точок
  auto ideal_pt = ideal(points);
  auto nadir_pt = nadir(points);
  ```

#### 3. Метрики оцінки обмежень

- **Кількість порушених обмежень**:
  ```cpp
  // Перевірка виконання обмежень-рівностей
  auto eq_result = detail::test_eq_constraints(eq_first, eq_last, tol_first);
  auto n_satisfied = eq_result.first;  // Кількість задоволених обмежень
  auto violation_norm = eq_result.second;  // L2-норма порушення
  ```

### Можливості логування та збору даних

PaGMO2 реалізує гнучку систему логування для всіх алгоритмів через механізм параметра `verbosity` та методу `get_log()`:

#### 1. Внутрішнє логування алгоритмів

- **Встановлення рівня деталізації**:
  ```cpp
  // Налаштування рівня логування
  algo.set_verbosity(1);  // Логування лише покращень
  algo.set_verbosity(10); // Логування кожні 10 поколінь
  ```

- **Структура логу**: залежить від конкретного алгоритму, але зазвичай містить:
  - Номер покоління/ітерації
  - Кількість обчислень функції (fevals)
  - Найкращий результат
  - Метрики конвергенції (dx, df)
  - Алгоритм-специфічні параметри

  Наприклад, для алгоритму DE лог має структуру:
  ```
  Gen, Fevals, Best, dx, df
  ```

- **Отримання даних логу**:
  ```cpp
  const auto &log = algo.get_log();

  // Аналіз даних з логу
  for (const auto &entry : log) {
      auto gen = std::get<0>(entry);
      auto fevals = std::get<1>(entry);
      auto best = std::get<2>(entry);
      // ...
  }
  ```

#### 2. Виведення та форматування даних

PaGMO2 надає базові утиліти для виведення інформації:

- **Потокове виведення**: основні класи підтримують стандартний оператор `<<`
  ```cpp
  std::cout << pop << std::endl;  // Виведення інформації про популяцію
  std::cout << algo << std::endl; // Виведення інформації про алгоритм
  ```

- **Форматування текстових таблиць**:
  ```cpp
  // Приклад форматування логу у вигляді таблиці
  std::cout << "Gen:        Fevals:          Best:   dx:       df:" << std::endl;
  for (const auto &entry : log) {
      std::cout << std::get<0>(entry) << "           "
                << std::get<1>(entry) << "           "
                << std::get<2>(entry) << "           "
                // ...
                << std::endl;
  }
  ```

### Збереження та аналіз результатів

#### 1. Серіалізація даних

PaGMO2 підтримує серіалізацію через бібліотеку Boost:

```cpp
// Серіалізація популяції
std::ofstream ofs("population.bin");
boost::archive::binary_oarchive oa(ofs);
oa << pop;

// Десеріалізація
std::ifstream ifs("population.bin");
boost::archive::binary_iarchive ia(ifs);
population restored_pop;
ia >> restored_pop;
```

#### 2. Експорт даних для зовнішнього аналізу

Хоча PaGMO2 не має вбудованих інструментів візуалізації, він дозволяє легко експортувати дані для аналізу зовнішніми засобами:

```cpp
// Експорт вектора рішень популяції
std::vector<vector_double> decision_vectors;
for (decltype(pop.size()) i = 0; i < pop.size(); ++i) {
    decision_vectors.push_back(pop.get_x()[i]);
}

// Експорт значень фітнес-функції
std::vector<vector_double> fitness_values;
for (decltype(pop.size()) i = 0; i < pop.size(); ++i) {
    fitness_values.push_back(pop.get_f()[i]);
}

// Запис даних у файл (приклад для CSV формату)
std::ofstream output_file("results.csv");
for (size_t i = 0; i < fitness_values.size(); ++i) {
    // Запис рішення
    for (auto val : decision_vectors[i]) {
        output_file << val << ",";
    }

    // Запис значень фітнес-функції
    for (auto val : fitness_values[i]) {
        output_file << val << ",";
    }
    output_file << std::endl;
}
```

### Порівняння алгоритмів та налаштувань

PaGMO2 не надає спеціалізованих засобів для порівняння алгоритмів, але пропонує кілька підходів:

#### 1. Паралельне виконання з різними налаштуваннями

```cpp
// Створення кількох алгоритмів з різними параметрами
algorithm algo1{sga(100, 0.8, 1.0, 0.02, 1.0)};
algorithm algo2{de(100, 0.8, 0.9, 2)};
algorithm algo3{simulated_annealing()};

// Виконання алгоритмів на одній задачі
problem prob{schwefel(30)};
population pop1{prob, 20};
population pop2{prob, 20};
population pop3{prob, 20};

pop1 = algo1.evolve(pop1);
pop2 = algo2.evolve(pop2);
pop3 = algo3.evolve(pop3);

// Порівняння результатів
std::cout << "SGA best: " << pop1.champion_f()[0] << std::endl;
std::cout << "DE best: " << pop2.champion_f()[0] << std::endl;
std::cout << "SA best: " << pop3.champion_f()[0] << std::endl;
```

#### 2. Використання архіпелагу для експериментів

```cpp
// Створення архіпелагу з різними алгоритмами
archipelago archi;
archi.push_back(island{algo1, prob, 20});
archi.push_back(island{algo2, prob, 20});
archi.push_back(island{algo3, prob, 20});

// Паралельна еволюція
archi.evolve();
archi.wait_check();

// Порівняння результатів
for (size_t i = 0; i < archi.size(); ++i) {
    std::cout << "Algorithm " << i << " best: "
              << archi[i].get_population().champion_f()[0]
              << std::endl;
}
```

### Формати збереження операторів та оптимізованих моделей

PaGMO2 підтримує кілька підходів до збереження операторів, алгоритмів та результатів:

#### 1. Серіалізація алгоритмів та операторів

Завдяки підтримці серіалізації Boost, можна зберігати та відновлювати стан алгоритмів разом з їх операторами:

```cpp
// Серіалізація налаштованого алгоритму
algorithm tuned_algo{sga(100, 0.85, 25.0, 0.02, 35.0, 3, "sbx", "polynomial", "tournament")};
std::ofstream ofs("tuned_sga.bin");
boost::archive::binary_oarchive oa(ofs);
oa << tuned_algo;

// Завантаження алгоритму з усіма операторами
std::ifstream ifs("tuned_sga.bin");
boost::archive::binary_iarchive ia(ifs);
algorithm loaded_algo;
ia >> loaded_algo;
```

#### 2. Збереження метаданих операторів у JSON форматі

Для кращої міжплатформної сумісності та читабельності можна зберігати параметри операторів у JSON форматі:

```cpp
// Створення структури для збереження налаштувань
std::map<std::string, nlohmann::json> operator_settings;

// Збереження налаштувань операторів селекції
operator_settings["selection"] = {
    {"type", "tournament"},
    {"tournament_size", 3},
    {"selection_pressure", "high"}
};

// Збереження налаштувань кросинговеру
operator_settings["crossover"] = {
    {"type", "sbx"},
    {"probability", 0.85},
    {"distribution_index", 25.0}
};

// Збереження налаштувань мутації
operator_settings["mutation"] = {
    {"type", "polynomial"},
    {"probability", 0.02},
    {"distribution_index", 35.0}
};

// Запис у файл
std::ofstream json_out("operator_settings.json");
json_out << nlohmann::json(operator_settings).dump(4);
```

#### 3. Створення бібліотеки оптимізованих операторів

Для ефективного повторного використання можна створювати фабрики операторів:

```cpp
// Приклад фабрики операторів кросинговеру
class crossover_factory {
public:
    static std::function<void(vector_double&, vector_double&,
                            const std::pair<vector_double, vector_double>&,
                            detail::random_engine_type&)>
    get_sbx_for_tsp() {
        // Повернення спеціалізованого SBX оператора для задачі комівояжера
        return custom_tsp_sbx;
    }

    static std::function<void(vector_double&, vector_double&,
                            const std::pair<vector_double, vector_double>&,
                            detail::random_engine_type&)>
    get_order_crossover() {
        // Повернення оператора OX для перестановочних задач
        return order_crossover;
    }

    // Інші спеціалізовані оператори...
private:
    // Реалізації операторів
    static void custom_tsp_sbx(...) { /* ... */ }
    static void order_crossover(...) { /* ... */ }
};
```

### Комплексні критерії якості для оцінки алгоритмів

Для всебічної оцінки генетичних алгоритмів рекомендується використовувати багатовимірний підхід:

#### 1. Критерії ефективності пошуку

- **Якість знайдених рішень**:
  - Абсолютне відхилення від відомого оптимуму (для тестових функцій)
  - Відносне відхилення для порівняння між алгоритмами
  - Статистичні характеристики (середнє, медіана, стандартне відхилення) при багаторазових запусках

- **Швидкість збіжності**:
  - Кількість поколінь до досягнення заданого рівня точності
  - Кількість обчислень фітнес-функції до досягнення заданого рівня точності
  - Швидкість покращення найкращого рішення (перша похідна прогресу)

- **Стабільність роботи**:
  - Дисперсія результатів при різних запусках
  - Коефіцієнт варіації результатів
  - Робастність до змін початкових умов

#### 2. Багатокритеріальні метрики

- **Гіперобʼєм та його динаміка**:
  ```python
  # Відстеження зміни гіперобʼєму з часом
  hv_history = []
  for gen in range(0, 100, 10):
      algo = pg.algorithm(pg.nsga2(gen))
      pop = pg.population(prob, 100)
      pop = algo.evolve(pop)

      # Отримання недомінованих точок
      ndf, _, _, _ = pg.fast_non_dominated_sorting(pop.get_f())
      non_dom_points = np.array([pop.get_f()[i] for i in ndf[0]])

      # Обчислення гіперобʼєму
      hv = pg.hypervolume(non_dom_points)
      hv_history.append(hv.compute(reference_point))
  ```

- **Швидкість наближення до Парето-фронту**:
  - Генераційна відстань (Generational Distance, GD)
  - Інвертована генераційна відстань (Inverted Generational Distance, IGD)
  - Відстань до референсної множини

- **Якість розподілу рішень**:
  - Spacing метрика (рівномірність розподілу точок)
  - Spread метрика (розтягнутість уздовж Парето-фронту)
  - Density метрика (щільність покриття Парето-фронту)

#### 3. Обчислювальна ефективність

- **Час виконання**:
  - Повний час виконання алгоритму
  - Час обчислення однієї ітерації
  - Масштабованість при збільшенні розмірності задачі

- **Ефективність паралелізації**:
  - Прискорення (Speedup) при збільшенні кількості обчислювальних ресурсів
  - Ефективність (Efficiency) використання паралельних ресурсів
  - Масштабованість на багатоядерних та розподілених системах

### Комплексна методологія експериментального аналізу

Для отримання достовірних та статистично значимих результатів рекомендується дотримуватись наступної методології:

#### 1. Підготовка тестового середовища

```cpp
// Функція оцінки алгоритму на наборі тестових задач
std::map<std::string, std::vector<vector_double>> evaluate_algorithm(
    const algorithm &algo,
    const std::vector<problem> &test_problems,
    unsigned n_runs = 30) {

    std::map<std::string, std::vector<vector_double>> results;

    for (const auto &prob : test_problems) {
        std::vector<vector_double> problem_results;

        for (unsigned run = 0; run < n_runs; ++run) {
            // Ініціалізація з різними seed
            population pop(prob, 50, run);

            // Еволюція
            pop = algo.evolve(pop);

            // Збереження результатів
            problem_results.push_back(pop.champion_f());
        }

        results[prob.get_name()] = problem_results;
    }

    return results;
}
```

#### 2. Порівняльний аналіз кількох алгоритмів

```cpp
// Функція для статистичного порівняння кількох алгоритмів
void compare_algorithms(
    const std::vector<std::pair<std::string, algorithm>> &algorithms,
    const std::vector<problem> &test_problems) {

    std::map<std::string, std::map<std::string, statistics>> stats;

    for (const auto &[name, algo] : algorithms) {
        auto results = evaluate_algorithm(algo, test_problems);

        for (const auto &[prob_name, prob_results] : results) {
            // Обчислення статистик
            double mean = /* ... */;
            double median = /* ... */;
            double std_dev = /* ... */;
            double best = /* ... */;
            double worst = /* ... */;

            stats[prob_name][name] = {mean, median, std_dev, best, worst};
        }
    }

    // Статистичні тести
    for (const auto &[prob_name, algo_stats] : stats) {
        // Виконання тесту Вілкоксона або Фрідмана
        // для перевірки статистичної значимості різниці
    }

    // Візуалізація та експорт результатів
}
```

#### 3. Система критеріїв для інтегральної оцінки

```python
# Приклад інтегральної оцінки алгоритму в Python
def comprehensive_evaluation(algorithm_name, results):
    # Обчислення нормалізованих метрик
    solution_quality = normalize_quality(results['quality'])
    convergence_speed = normalize_speed(results['convergence'])
    robustness = normalize_robustness(results['robustness'])
    diversity = normalize_diversity(results['diversity'])
    computational_efficiency = normalize_efficiency(results['efficiency'])

    # Обчислення інтегрального показника
    # з ваговими коефіцієнтами для різних аспектів
    weights = {
        'quality': 0.35,
        'convergence': 0.25,
        'robustness': 0.15,
        'diversity': 0.15,
        'efficiency': 0.10
    }

    overall_score = (
        weights['quality'] * solution_quality +
        weights['convergence'] * convergence_speed +
        weights['robustness'] * robustness +
        weights['diversity'] * diversity +
        weights['efficiency'] * computational_efficiency
    )

    return {
        'algorithm': algorithm_name,
        'overall_score': overall_score,
        'detailed_scores': {
            'solution_quality': solution_quality,
            'convergence_speed': convergence_speed,
            'robustness': robustness,
            'diversity': diversity,
            'computational_efficiency': computational_efficiency
        }
    }
```

### Обмеження та рекомендації для експериментального аналізу

1. **Відсутність вбудованої візуалізації**: Для візуального аналізу рекомендується експортувати дані та використовувати зовнішні інструменти:
   - Python з matplotlib/seaborn для графіків
   - R для статистичного аналізу
   - Спеціалізовані інструменти для візуалізації Парето-фронтів

2. **Обмежена підтримка статистичного аналізу**: Для достовірних результатів рекомендується:
   - Виконувати багаторазові запуски з різними значеннями seed
   - Використовувати зовнішні інструменти для статистичної обробки результатів
   - Застосовувати непараметричні тести для порівняння алгоритмів

3. **Розширення через інтеграцію з Python**:
   ```python
   # Використання pygmo з matplotlib для візуалізації Парето-фронту
   import pygmo as pg
   import matplotlib.pyplot as plt
   import numpy as np

   # Створення та оптимізація в pygmo
   prob = pg.problem(pg.zdt(1))
   algo = pg.algorithm(pg.nsga2(100))
   pop = pg.population(prob, 100)
   pop = algo.evolve(pop)

   # Отримання недомінованих рішень
   ndf, dl, dc, ndr = pg.fast_non_dominated_sorting(pop.get_f())
   ndf_points = np.array([pop.get_f()[i] for i in ndf[0]])

   # Візуалізація
   plt.scatter(ndf_points[:, 0], ndf_points[:, 1])
   plt.xlabel('f1')
   plt.ylabel('f2')
   plt.title('Pareto Front')
   plt.savefig('pareto_front.png')
   ```

### Рекомендовані практики експериментального аналізу

Для досягнення максимальної ефективності в експериментальному аналізі рекомендується:

1. **Структурувати експерименти**:
   - Розробити чіткий план експериментів з визначеними метриками
   - Визначити статистично значимий розмір вибірки (кількість запусків)
   - Стандартизувати процес збору та аналізу даних

2. **Автоматизувати процес експериментів**:
   ```cpp
   // Приклад автоматизації запусків з різними параметрами
   std::vector<double> cr_values = {0.7, 0.8, 0.9, 1.0};
   std::vector<double> m_values = {0.01, 0.02, 0.05, 0.1};

   // Результати експериментів
   std::map<std::pair<double, double>, std::vector<double>> results;

   // Виконання експериментів
   for (auto cr : cr_values) {
       for (auto m : m_values) {
           for (int seed = 1; seed <= 30; ++seed) {
               algorithm algo{sga(100, cr, 1.0, m, 1.0, 2,
                             "exponential", "polynomial", "tournament", seed)};
               population pop{prob, 20};
               pop = algo.evolve(pop);

               // Збереження результату
               results[{cr, m}].push_back(pop.champion_f()[0]);
           }
       }
   }

   // Аналіз та експорт результатів
   // ...
   ```

3. **Створити стандартний формат звітів**:
   - Включати інформацію про налаштування, параметри та умови експериментів
   - Надавати як статистичні метрики, так і аналіз розподілу результатів
   - Візуалізувати як кінцеві результати, так і динаміку сходимості

Хоча PaGMO2 не надає повноцінного фреймворку для експериментального аналізу, бібліотека надає необхідні базові інструменти та метрики для збору даних. Поєднуючи ці можливості з зовнішніми засобами статистичного аналізу та візуалізації, користувачі можуть проводити комплексні дослідження ефективності та робастності оптимізаційних алгоритмів.
